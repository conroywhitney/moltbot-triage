---
number: 3297
title: "feat(models): add OPENAI_BASE_URL env override for OpenAI-compatible endpoints"
author: sjhddh
created: 2026-01-28T11:23:34Z
updated: 2026-01-28T23:25:09Z
labels: ["docs", "gateway", "agents"]
additions: 265
deletions: 2
changed_files: 5
size: large
review_decision: none
reviews: []
comments_count: 0
reactions_total: 0
ci_status: failing
mergeable: unknown
draft: false
url: https://github.com/moltbot/moltbot/pull/3297
fixes_issues: []
related_prs: []
duplicate_of: null
---

## Description

## Summary

Adds support for redirecting all `openai/*` model requests to any OpenAI-compatible endpoint via the `OPENAI_BASE_URL` environment variable—no config file changes needed.

This enables users to easily point Moltbot at LiteLLM, vLLM, LM Studio, or any other OpenAI-compatible proxy while keeping the familiar `openai/gpt-*` model references.

**Two patterns now supported:**

1. **Drop-in override** (new): `export OPENAI_BASE_URL="http://localhost:8000/v1"` + keep using `openai/gpt-5.2`
2. **Custom provider** (existing): define `models.providers.myproxy` with custom `baseUrl/apiKey/api` + use `myproxy/<model>`

## Changes

- **`src/agents/models-config.providers.ts`**: Add `resolveImplicitOpenAiProvider()` that reads `OPENAI_BASE_URL` and returns `{ baseUrl, models: [] }` to preserve the built-in model catalog
- **`src/agents/models-config.ts`**: Integrate implicit OpenAI provider into the models.json generation (explicit config takes precedence)
- **`docs/concepts/model-providers.md`**: Document both patterns + add "Other OpenAI-compatible surfaces" section (embeddings, media, TTS)
- **`docs/gateway/configuration.md`**: Add quick-start callout for OPENAI_BASE_URL override
- **Tests**: Add unit + integration tests for the new override behavior

## Test plan

- [ ] Unit tests pass for `resolveImplicitOpenAiProvider` (null handling, baseUrl extraction, whitespace trimming)
- [ ] Integration tests verify models.json generation with/without OPENAI_BASE_URL
- [ ] Explicit `models.providers.openai.baseUrl` takes precedence over env var
- [ ] Manual: set `OPENAI_BASE_URL` → verify `openai/*` requests go to custom endpoint

## Reviews


## Comments


## Stats

- **Size:** large (265+, 2-, 5 files)
- **Age:** 1 days
- **Last activity:** 2026-01-28

## Links

- Fixes: (none detected)

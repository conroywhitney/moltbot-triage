---
number: 3958
title: "[AI-Assisted] feat(security): add prompt injection defense with pattern detection"
author: ronit111
created: 2026-01-29T12:20:35Z
updated: 2026-01-29T12:21:25Z
labels: []
additions: 858
deletions: 0
changed_files: 3
size: large
review_decision: none
reviews: []
comments_count: 0
reactions_total: 0
ci_status: failing
mergeable: unknown
draft: false
url: https://github.com/openclaw/openclaw/pull/3958
fixes_issues: []
related_prs: []
duplicate_of: null
---

## Description

## Summary
- Add comprehensive prompt injection detection for user input
- Pattern-based scanning across 7 categories: instruction override, role impersonation, prompt extraction, jailbreak, encoding tricks, delimiter attacks, command injection
- Risk scoring system (0-100) with configurable thresholds
- Configurable response actions: log, warn, sanitize, or block
- `quickCheck()` for fast preliminary filtering on high-volume input
- 36 unit tests covering all detection categories and configuration options

## Test plan
- [x] `pnpm lint` passes
- [x] `pnpm build` passes  
- [x] `pnpm vitest run src/infra/prompt-injection.test.ts` - all 36 tests pass

## Usage
```typescript
import { scanForInjection, scanAndRespond } from "./infra/prompt-injection.js";

// Basic scan
const result = scanForInjection(userInput);
if (!result.isClean) {
  console.log(`Risk score: ${result.riskScore}`);
}

// Scan with configured response
const response = scanAndRespond(userInput, {
  action: "block",
  riskThreshold: 50,
});
if (!response.allowed) {
  // Block the message
}
```

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

## Reviews


## Comments


## Stats

- **Size:** large (858+, 0-, 3 files)
- **Age:** 1 days
- **Last activity:** 2026-01-29

## Links

- Fixes: (none detected)

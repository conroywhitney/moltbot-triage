---
number: 3895
title: "perf: mathematical optimization of vision pipeline via deterministic scaling"
author: adarshsen592-create
created: 2026-01-29T09:40:31Z
updated: 2026-02-03T03:52:41Z
labels: []
additions: 35
deletions: 42
changed_files: 1
size: medium
review_decision: none
reviews: [{"author":"knocte","state":"COMMENTED"},{"author":"greptile-apps","state":"COMMENTED"}]
comments_count: 5
reactions_total: 2
ci_status: failing
mergeable: unknown
draft: false
url: https://github.com/openclaw/openclaw/pull/3895
fixes_issues: [3870]
related_prs: [3870,3875]
duplicate_of: null
---

## Description

This PR addresses the high CPU overhead and memory crashes in the screenshot normalization process (Fixes #3870, #3875).

Changes: > - Replaced iterative resizing loops with a single-pass O(1) scale calculation.

Implemented area-to-byte proportionality logic (Square Root Law) for precise sizing.

Reduced ingestion latency significantly for high-resolution displays.

<!-- greptile_comment -->

<h2>Greptile Overview</h2>

<h3>Greptile Summary</h3>

This PR replaces the prior “grid search” screenshot normalization (multiple resize+quality attempts until under `maxBytes`) with a single-pass deterministic scaling computation based on dimension and byte-budget ratios.

The change is localized to `src/browser/screenshot.ts`, which is used by the browser snapshot routes to constrain screenshot payload size before saving/serving.

Main issues:
- The updated file currently references removed imports/constants (`getImageMetadata`, `resizeToJpeg`, `DEFAULT_BROWSER_SCREENSHOT_MAX_*`), which should break compilation.
- The new return type/contentType implies JPEG output for all paths, but the early-exit can return a non-JPEG input buffer while labeling it as `image/jpeg`.
- The deterministic byte scaling is heuristic; without a post-check/fallback, outputs can still exceed `maxBytes` for certain screenshot content.

<h3>Confidence Score: 1/5</h3>

- Not safe to merge as-is due to likely compile/runtime breakage and incorrect contentType guarantees.
- `src/browser/screenshot.ts` appears to have removed required imports/exports but still references them, which should fail to build. Additionally, the function now claims to always return JPEG while the early-exit can return the original (possibly PNG) buffer, which can break downstream consumers relying on contentType/buffer alignment.
- src/browser/screenshot.ts

<!-- greptile_other_comments_section -->

<sub>(2/5) Greptile learns from your feedback when you react with thumbs up/down!</sub>

**Context used:**

- Context from `dashboard` - CLAUDE.md ([source](https://app.greptile.com/review/custom-context?memory=fd949e91-5c3a-4ab5-90a1-cbe184fd6ce8))
- Context from `dashboard` - AGENTS.md ([source](https://app.greptile.com/review/custom-context?memory=0d0c8278-ef8e-4d6c-ab21-f5527e322f13))

<!-- /greptile_comment -->

## Reviews

### @knocte — COMMENTED (2026-01-29)



### @greptile-apps — COMMENTED (2026-02-03)

<sub>1 file reviewed, 4 comments</sub>

<sub>[Edit Code Review Agent Settings](https://app.greptile.com/review/github) | [Greptile](https://greptile.com?utm_source=greptile_expert&utm_medium=github&utm_campaign=code_reviews)</sub>


## Comments

### @knocte (2026-01-29)

You should edit PR description to add the text `Fixes https://github.com/moltbot/moltbot/issues/3870` at the end of it, otherwise they are not linked properly.

### @sebastienbo (2026-01-29)

Great code, this addresses really the core of smolbot (clawdbot) . 
This beatifull math makes smolbot much more efficient for a process that happens again and again by everybody.

Thank you for your contribution and mathematical solution to reduce Big O bottlenecks

### @sebastienbo (2026-01-29)

This was mac related: Is it possible that the same problem also exists in the windows platform? Because this is an algorythmic problem, we can assume the same algorithm was used for the windows platform. I hope these changes will be comitted in beta.2 , that way we can test if the crashing problems are solved.

CPU and RAM efficiency are critical for agentic tasks, otherwise token consumption explodes while processing time also explodes (waiting for round-trip towards a thinking model).

Something else this repo misses is system resources protection: when spawning new agents, the master task should first look at the current overall cpu usage: If it is higher then 80% it should NOT spawn new tasks, otherwise you overheat the cpu and everything becomes slow. This logic allows smolbot to auto-scale based on the hardware it is deployed. For example if i'm on a single core vps then this logic would block me from doing two tasks at the same time. But if I have 16 cores, it will probably be able to spawn much more concurrent tasks. This logic makes sure your cpu doesn't shoke. ANd on a laptop this means your laptop stays cooler because it is not forced to go to 100% of it's capacity for smolbot alone (it gives some breathing room for your other system processes).
**This logic should be build into the thinking(orchestrator) core of smolbot(clawdbot).**

### @adarshsen592-create (2026-01-29)

Hey Sebastienbo ,
Love your dedication for this , yeah your thinking is right coz and this
problem was not only considered for Mac but also for Windows as this code
is too heavy to run and not so efficiently written by this Clawdbot team so
the solution developed by me is universal and not only for Mac users this
just makes the entire code processing exactly 42 times faster
mathematically . If you are equally interested in this topic should we
connect on a platform eg- Discord, Instagram.
Thank you
Adarsh

On Thu, Jan 29, 2026, 4:58 PM Sébastien Bo ***@***.***> wrote:

> *sebastienbo* left a comment (moltbot/moltbot#3895)
> <https://github.com/moltbot/moltbot/pull/3895#issuecomment-3817060320>
>
> Is it possible that the same problem also exists in the windows binary?
> Because this is an algorythmic problem, we can assume the same algorithm
> was used for the windows platform
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/moltbot/moltbot/pull/3895#issuecomment-3817060320>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/B3RETI4DNLGF343EUDZC4DL4JHVETAVCNFSM6AAAAACTJD6XXGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZTQMJXGA3DAMZSGA>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>


### @greptile-apps (2026-02-03)

<details>
<summary>Additional Comments (2)</summary>

**`src/browser/screenshot.ts`**
[P1] Division-by-zero/NaN scaling when metadata missing

If `getImageMetadata` fails and returns 0/0, `dimensionScale` becomes `maxSide / 0` (Infinity) and `byteScale` may be finite, but `newWidth/newHeight` become `Math.round(0 * targetScale)` → 0 → clamped to 1. That can trigger an expensive re-encode to a 1×1 JPEG for unknown/unsupported image types, and it also drops the previous behavior that treated “unknown dimensions” as a special-case. Consider explicitly handling `width<=0 || height<=0` before computing scales.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/browser/screenshot.ts
Line: 29:34

Comment:
[P1] Division-by-zero/NaN scaling when metadata missing

If `getImageMetadata` fails and returns 0/0, `dimensionScale` becomes `maxSide / 0` (Infinity) and `byteScale` may be finite, but `newWidth/newHeight` become `Math.round(0 * targetScale)` → 0 → clamped to 1. That can trigger an expensive re-encode to a 1×1 JPEG for unknown/unsupported image types, and it also drops the previous behavior that treated “unknown dimensions” as a special-case. Consider explicitly handling `width<=0 || height<=0` before computing scales.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/browser/screenshot.ts`**
[P2] The “square root law” byte scaling assumption is brittle for screenshots

`byteScale = sqrt(maxBytes / buffer.byteLength)` assumes encoded size is proportional to pixel area, but screenshot formats vary widely with content (flat UI vs photo), encoder (mozjpeg), and chosen quality. The 0.95 safety margin helps but still can produce outputs above `maxBytes` with no retry/guard. Even a simple post-check (and one fallback re-encode) would make this deterministic scaling safer.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/browser/screenshot.ts
Line: 36:40

Comment:
[P2] The “square root law” byte scaling assumption is brittle for screenshots

`byteScale = sqrt(maxBytes / buffer.byteLength)` assumes encoded size is proportional to pixel area, but screenshot formats vary widely with content (flat UI vs photo), encoder (mozjpeg), and chosen quality. The 0.95 safety margin helps but still can produce outputs above `maxBytes` with no retry/guard. Even a simple post-check (and one fallback re-encode) would make this deterministic scaling safer.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>
</details>


## Stats

- **Size:** medium (35+, 42-, 1 files)
- **Age:** 4 days
- **Last activity:** 2026-02-03

## Links

- Fixes: #3870

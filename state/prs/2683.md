---
number: 2683
title: "feat(providers): add LiteLLM provider support"
author: hiboute
created: 2026-01-27T08:50:57Z
updated: 2026-01-30T11:59:46Z
labels: ["docs", "cli", "commands", "agents"]
additions: 821
deletions: 85
changed_files: 21
size: large
review_decision: none
reviews: [{"author":"chatgpt-codex-connector","state":"COMMENTED"}]
comments_count: 5
reactions_total: 1
ci_status: pending
mergeable: true
draft: false
url: https://github.com/openclaw/openclaw/pull/2683
fixes_issues: [2305,2639]
related_prs: [2305,2639]
duplicate_of: null
---

## Description

## Summary
- Adds LiteLLM as a new model provider for OpenAI-compatible proxy support
- Fetches available models from LiteLLM during onboarding via `/v1/models` and `/model/info` endpoints
- Auto-detects context window and max output tokens from model metadata
- Adds `compat.supportsStore: false` to avoid "Extra inputs are not permitted" errors when proxying to Anthropic/other providers
- Supports CLI flags for non-interactive automation (`--litellm-api-key`, `--litellm-base-url`, `--litellm-model`)
- Implements graceful error recovery when LiteLLM connection fails:
  - Shows helpful error message with possible causes (invalid API key, server unreachable, network issues)
  - Offers retry options: re-enter API key, re-enter base URL
  - Allows navigating back to auth method selection without crashing
- Removes manual model entry prompts during onboarding (models are auto-fetched)
- Adds proper error handling across all onboarding entry points to prevent `AUTH_CHOICE_CANCELLED` errors

Closes #2639
Closes #2305

## Test plan
- [x] Build passes (`pnpm build`)
- [x] Lint passes (`pnpm lint`)
- [x] Run `openclaw onboard --auth-choice litellm-api-key` and verify model selection works
- [x] Verify context window is auto-detected from LiteLLM
- [x] Test error recovery when LiteLLM server is unreachable
- [x] Test retry flows (re-enter API key, re-enter base URL)
- [x] Verify "Go back to auth method selection" properly returns to auth choice menu

## Reviews

### @chatgpt-codex-connector ‚Äî COMMENTED (2026-01-27)


### üí° Codex Review

Here are some automated review suggestions for this pull request.

**Reviewed commit:** `b3cf29edd2`
    

<details> <summary>‚ÑπÔ∏è About Codex in GitHub</summary>
<br/>

[Your team has set up Codex to review pull requests in this repo](http://chatgpt.com/codex/settings/general). Reviews are triggered when you
- Open a pull request for review
- Mark a draft as ready
- Comment "@codex review".

If Codex has suggestions, it will comment; otherwise it will react with üëç.




Codex can also answer questions or update the PR. Try commenting "@codex address that feedback".
            
</details>


## Comments

### @hiboute (2026-01-27)

Thanks for catching this @chatgpt-codex-connector! Fixed in 9f2dbffa0 - the onboarding flow now honors `--litellm-api-key`, `--litellm-base-url`, and `--litellm-model` CLI flags for non-interactive/automation use cases.


### @chatgpt-codex-connector (2026-01-27)

To use Codex here, [create an environment for this repo](https://chatgpt.com/codex/settings/environments).

### @gmcouto (2026-01-27)

I don't think this closes #2086 

### @hiboute (2026-01-27)

> I don't think this closes #2086

If they use litellm, they can set whatever base url. it is not standar in clawdbot, but end result is here. But yes fine i agree with your pr.

### @illgitthat (2026-01-28)

I don't think this closes #2280 


## Stats

- **Size:** large (821+, 85-, 21 files)
- **Age:** 3 days
- **Last activity:** 2026-01-30

## Links

- Fixes: #2305
- Fixes: #2639

---
number: 4254
title: "feat: inject native command outputs into agent context"
author: Glucksberg
created: 2026-01-29T23:51:19Z
updated: 2026-01-30T00:29:41Z
labels: []
additions: 183
deletions: 3
changed_files: 7
size: medium
review_decision: none
reviews: []
comments_count: 0
reactions_total: 0
ci_status: pending
mergeable: unknown
draft: false
url: https://github.com/openclaw/openclaw/pull/4254
fixes_issues: []
related_prs: []
duplicate_of: null
---

## Description

## Summary
Capture outputs from native slash commands (`/models`, `/status`, `/model`, etc.) and inject them into the agent's context so it can understand what the user saw when following up with questions.

## Problem
When users run native commands like `/models` or `/status`, the response goes directly to them but the agent never sees it. This leads to confusion when users ask follow-up questions like "which providers do I have?" after running `/models`.

## Solution
- Store recent command outputs in the session entry
- Inject them into the agent's system prompt as "Recent Commands"
- Clear after injection to prevent repetition
- New `commands.injectToContext` config option (default: true) to opt-out

## Changes
- `sessions/types.ts`: Add `RecentCommandEntry` type
- `commands-core.ts`: Capture in handleCommands loop  
- `get-reply-directives.ts`: Capture for directive responses
- `get-reply-run.ts`: Format and inject into extraSystemPrompt
- Config files: Add `injectToContext` option

## Example
After user runs `/models`, agent sees:
```
## Recent Commands (user ran these before this message)
- `/models` (13s ago): Providers: | - anthropic (1) | - openai-codex (3)
```

## Testing
Tested manually with `/models`, `/status` commands via Telegram native commands.

## Reviews


## Comments


## Stats

- **Size:** medium (183+, 3-, 7 files)
- **Age:** 0 days
- **Last activity:** 2026-01-30

## Links

- Fixes: (none detected)

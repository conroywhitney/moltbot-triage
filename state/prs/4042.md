---
number: 4042
title: "agents: add proactive compaction before request"
author: freedomzt
created: 2026-01-29T15:39:34Z
updated: 2026-02-03T02:52:40Z
labels: ["agents"]
additions: 384
deletions: 0
changed_files: 5
size: large
review_decision: none
reviews: [{"author":"greptile-apps","state":"COMMENTED"}]
comments_count: 1
reactions_total: 1
ci_status: failing
mergeable: unknown
draft: false
url: https://github.com/openclaw/openclaw/pull/4042
fixes_issues: []
related_prs: [2347]
duplicate_of: null
---

## Description

## Summary

- Check session tokens before sending API request
- If estimated tokens exceed threshold (default 85%), run compaction **before** sending
- Prevents context overflow when large prompt + existing session > context limit

## Problem

Current compaction is **reactive**: request sent → API error → then compact. By the time compaction runs, there may not be enough space to even compact.

## Solution

Add proactive check before `runEmbeddedAttempt()`:

```typescript
const estimated = estimateMessagesTokens(session) + promptTokens;
if (estimated > threshold) {
  await compactEmbeddedPiSessionDirect(...);  // compact first
}
await runEmbeddedAttempt(...);  // then send
```

## New Config Options

```json
{
  "agents": {
    "defaults": {
      "compaction": {
        "proactiveEnabled": true,
        "proactiveThresholdRatio": 0.85
      }
    }
  }
}
```

## Test

```bash
pnpm test src/agents/pi-embedded-runner/proactive-compaction.test.ts
```

Related: #2347

<!-- greptile_comment -->

<h2>Greptile Overview</h2>

<h3>Greptile Summary</h3>

This PR adds a proactive compaction check to the embedded Pi agent runner: before sending an attempt, it estimates total tokens (session + prompt) and triggers `compactEmbeddedPiSessionDirect` when the estimate exceeds a configurable threshold. It introduces a new `proactive-compaction.ts` helper (session JSONL parsing + threshold resolution) and adds two new agent default config options (`proactiveEnabled`, `proactiveThresholdRatio`) with schema/type updates, plus a focused Vitest suite.

The change integrates into the existing compaction flow in `src/agents/pi-embedded-runner/run.ts` alongside the existing reactive “context overflow → compact → retry” loop, aiming to avoid situations where the request overflows before compaction can even run.

<h3>Confidence Score: 4/5</h3>

- This PR looks safe to merge with minor edge-case fixes.
- Core logic is straightforward and localized, and the new helper is covered by unit tests. Main risk is an edge case where the computed threshold becomes 0 and proactive compaction may run on every request for small-context / high-reserve configurations; also the prompt token heuristic may reduce effectiveness in some languages/inputs.
- src/agents/pi-embedded-runner/proactive-compaction.ts and src/agents/pi-embedded-runner/run.ts

<!-- greptile_other_comments_section -->

<sub>(2/5) Greptile learns from your feedback when you react with thumbs up/down!</sub>

**Context used:**

- Context from `dashboard` - CLAUDE.md ([source](https://app.greptile.com/review/custom-context?memory=fd949e91-5c3a-4ab5-90a1-cbe184fd6ce8))
- Context from `dashboard` - AGENTS.md ([source](https://app.greptile.com/review/custom-context?memory=0d0c8278-ef8e-4d6c-ab21-f5527e322f13))

<!-- /greptile_comment -->

## Reviews

### @greptile-apps — COMMENTED (2026-02-03)

<sub>3 files reviewed, 3 comments</sub>

<sub>[Edit Code Review Agent Settings](https://app.greptile.com/review/github) | [Greptile](https://greptile.com?utm_source=greptile_expert&utm_medium=github&utm_campaign=code_reviews)</sub>


## Comments

### @greptile-apps (2026-02-03)

<details>
<summary>Additional Comments (2)</summary>

**`src/agents/pi-embedded-runner/run.ts`**
[P2] Proactive check is based on `Math.ceil(params.prompt.length / 4)`, which is a rough char→token heuristic and can be far off for non-English text, lots of code/JSON, or tool schemas.

Since you already have `estimateTokens` used elsewhere (`src/agents/compaction.ts:16-18`), you may want to reuse the same token estimator for the outgoing prompt (or at least apply the same `SAFETY_MARGIN`) so proactive compaction triggers more consistently across inputs.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/agents/pi-embedded-runner/run.ts
Line: 302:310

Comment:
[P2] Proactive check is based on `Math.ceil(params.prompt.length / 4)`, which is a rough char→token heuristic and can be far off for non-English text, lots of code/JSON, or tool schemas.

Since you already have `estimateTokens` used elsewhere (`src/agents/compaction.ts:16-18`), you may want to reuse the same token estimator for the outgoing prompt (or at least apply the same `SAFETY_MARGIN`) so proactive compaction triggers more consistently across inputs.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/agents/pi-embedded-runner/proactive-compaction.test.ts`**
[P3] Tests use `as any` for config objects, which sidesteps the type-level contract you just extended.

This makes it easier for config shape regressions to slip through (e.g., wrong nesting). If feasible, prefer constructing a `MoltbotConfig` (or the minimal typed subset) instead of casting, so the tests fail when the config schema/types change.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/agents/pi-embedded-runner/proactive-compaction.test.ts
Line: 29:41

Comment:
[P3] Tests use `as any` for config objects, which sidesteps the type-level contract you just extended.

This makes it easier for config shape regressions to slip through (e.g., wrong nesting). If feasible, prefer constructing a `MoltbotConfig` (or the minimal typed subset) instead of casting, so the tests fail when the config schema/types change.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>
</details>


## Stats

- **Size:** large (384+, 0-, 5 files)
- **Age:** 4 days
- **Last activity:** 2026-02-03

## Links

- Fixes: (none detected)

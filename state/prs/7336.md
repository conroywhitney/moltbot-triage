---
number: 7336
title: "feat(channels): add reliability infrastructure"
author: Raistar22
created: 2026-02-02T18:14:19Z
updated: 2026-02-03T03:53:06Z
labels: []
additions: 1532
deletions: 0
changed_files: 10
size: huge
review_decision: none
reviews: [{"author":"greptile-apps","state":"COMMENTED"},{"author":"greptile-apps","state":"COMMENTED"},{"author":"greptile-apps","state":"COMMENTED"}]
comments_count: 1
reactions_total: 2
ci_status: pending
mergeable: true
draft: false
url: https://github.com/openclaw/openclaw/pull/7336
fixes_issues: []
related_prs: []
duplicate_of: null
---

## Description

- Add retry logic with exponential backoff and jitter
- Add idempotency store for deduplicating message delivery
- Add structured error handling with ChannelError types
- Add channel health monitoring infrastructure
- Add streaming response abstraction
- Extend typing signal API

<!-- greptile_comment -->

<h2>Greptile Overview</h2>

<h3>Greptile Summary</h3>

This PR introduces a set of reliability primitives for channel adapters: (1) a retry helper with exponential backoff + jitter, (2) an in-memory idempotency store and wrapper for deduplicating message handling, (3) structured channel error types/codes with basic detection/wrapping helpers, (4) a channel health registry/provider abstraction with optional periodic monitoring, (5) a streaming-response abstraction with throttled update handling, and (6) a unified typing-signal API with per-channel adapters and auto-stop.

These utilities live under `src/channels/{reliability,health,streaming}` and extend the existing typing module (`src/channels/typing.ts`) so channel implementations can share consistent retry/idempotency/error/stream/typing patterns rather than each adapter re-implementing them.

<h3>Confidence Score: 2/5</h3>

- This PR adds useful infrastructure but has a few correctness/resource-leak issues that should be addressed before merge.
- The core abstractions are reasonable, but there are several functional edge cases that can lead to incorrect behavior under load (idempotency TOCTOU, stream final flush dropping the last chunk, health provider replacement leaking intervals, maxSize not enforced) and some contract ambiguity (typing adapter stopTyping vs supportsExplicitStop). Fixing these should make the changes safe.
- src/channels/reliability/idempotency.ts, src/channels/streaming/stream-response.ts, src/channels/health/channel-health.ts

<!-- greptile_other_comments_section -->

<!-- /greptile_comment -->

## Reviews

### @greptile-apps — COMMENTED (2026-02-02)

<sub>4 files reviewed, 5 comments</sub>

<sub>[Edit Code Review Agent Settings](https://app.greptile.com/review/github) | [Greptile](https://greptile.com?utm_source=greptile_expert&utm_medium=github&utm_campaign=code_reviews)</sub>

### @greptile-apps — COMMENTED (2026-02-02)

<sub>4 files reviewed, 5 comments</sub>

<sub>[Edit Code Review Agent Settings](https://app.greptile.com/review/github) | [Greptile](https://greptile.com?utm_source=greptile_expert&utm_medium=github&utm_campaign=code_reviews)</sub>

### @greptile-apps — COMMENTED (2026-02-03)

<sub>6 files reviewed, 10 comments</sub>

<sub>[Edit Code Review Agent Settings](https://app.greptile.com/review/github) | [Greptile](https://greptile.com?utm_source=greptile_expert&utm_medium=github&utm_campaign=code_reviews)</sub>


## Comments

### @greptile-apps (2026-02-03)

<details>
<summary>Additional Comments (10)</summary>

**`src/channels/reliability/retry.ts`**
`withRetry()` ends with `throw lastError;` where `lastError` is typed as `unknown`. In TS/ES, `throw` is allowed for any value, but this makes the function effectively able to throw a non-`Error` (e.g., if `fn()` rejects with a string), which can break downstream error handling that assumes an `Error`. Consider normalizing here (e.g., `throw lastError instanceof Error ? lastError : new Error(String(lastError))`) or using a helper like your `wrapAsChannelError()` if you want structured errors.

<sub>Note: If this suggestion doesn't match your team's coding style, reply to this and let me know. I'll remember it for next time!</sub>

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/reliability/retry.ts
Line: 1131:1132

Comment:
`withRetry()` ends with `throw lastError;` where `lastError` is typed as `unknown`. In TS/ES, `throw` is allowed for any value, but this makes the function effectively able to throw a non-`Error` (e.g., if `fn()` rejects with a string), which can break downstream error handling that assumes an `Error`. Consider normalizing here (e.g., `throw lastError instanceof Error ? lastError : new Error(String(lastError))`) or using a helper like your `wrapAsChannelError()` if you want structured errors.

<sub>Note: If this suggestion doesn't match your team's coding style, reply to this and let me know. I'll remember it for next time!</sub>

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/typing.ts`**
`TypingAdapter` always requires a callable `stopTyping`, but `createTypingAdapter()` supplies a no-op when `stopTyping` isn’t actually supported while also setting `supportsExplicitStop: false`. This makes the contract ambiguous for consumers (method exists but feature flag says it shouldn’t be used). Consider making `stopTyping` optional on the interface (and only present when supported) or splitting into two adapter shapes so the type aligns with `supportsExplicitStop`.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/typing.ts
Line: 1456:1464

Comment:
`TypingAdapter` always requires a callable `stopTyping`, but `createTypingAdapter()` supplies a no-op when `stopTyping` isn’t actually supported while also setting `supportsExplicitStop: false`. This makes the contract ambiguous for consumers (method exists but feature flag says it shouldn’t be used). Consider making `stopTyping` optional on the interface (and only present when supported) or splitting into two adapter shapes so the type aligns with `supportsExplicitStop`.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/reliability/errors.ts`**
`ChannelErrorCode.IDEMPOTENCY_CONFLICT` is defined but isn’t included in either `RECOVERABLE_ERROR_CODES` or `PERMANENT_ERROR_CODES`, so `ChannelError.recoverable` will default to `false`. If idempotency conflicts are expected/benign duplicates (or should be handled specially), it’s worth classifying them explicitly to avoid callers treating duplicates as hard failures.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/reliability/errors.ts
Line: 285:299

Comment:
`ChannelErrorCode.IDEMPOTENCY_CONFLICT` is defined but isn’t included in either `RECOVERABLE_ERROR_CODES` or `PERMANENT_ERROR_CODES`, so `ChannelError.recoverable` will default to `false`. If idempotency conflicts are expected/benign duplicates (or should be handled specially), it’s worth classifying them explicitly to avoid callers treating duplicates as hard failures.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/reliability/idempotency.ts`**
`createInMemoryIdempotencyStore()` starts an internal `setInterval(prune, pruneIntervalMs)` but the returned `IdempotencyStore` API has no way to stop/dispose it. Even with `unref()`, the interval keeps running and can leak resources if multiple stores are created (tests, per-adapter instances, etc.). Consider exposing a `dispose()`/`stop()` method or returning the timer handle so callers can `clearInterval` when done.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/reliability/idempotency.ts
Line: 505:511

Comment:
`createInMemoryIdempotencyStore()` starts an internal `setInterval(prune, pruneIntervalMs)` but the returned `IdempotencyStore` API has no way to stop/dispose it. Even with `unref()`, the interval keeps running and can leak resources if multiple stores are created (tests, per-adapter instances, etc.). Consider exposing a `dispose()`/`stop()` method or returning the timer handle so callers can `clearInterval` when done.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/reliability/idempotency.ts`**
`createInMemoryIdempotencyStore().set()` doesn’t actually enforce `maxSize`: when `store.size >= maxSize` and none are expired, `prune()` removes nothing and `store.set(...)` still adds a new entry, allowing unbounded growth past `maxSize`. If `maxSize` is intended as a hard cap, re-check after pruning and either evict an entry (oldest/LRU) or refuse the insert.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/reliability/idempotency.ts
Line: 526:532

Comment:
`createInMemoryIdempotencyStore().set()` doesn’t actually enforce `maxSize`: when `store.size >= maxSize` and none are expired, `prune()` removes nothing and `store.set(...)` still adds a new entry, allowing unbounded growth past `maxSize`. If `maxSize` is intended as a hard cap, re-check after pruning and either evict an entry (oldest/LRU) or refuse the insert.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/reliability/idempotency.ts`**
`withIdempotency()` does `await store.has(key)` and then `await store.set(key, ttlMs)`. With two concurrent calls for the same key, both can observe `has=false` before either `set()` runs, causing double execution and defeating deduplication under load. This needs an atomic “set-if-absent/claim” operation in the store API (or a synchronous critical section in the in-memory store).

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/reliability/idempotency.ts
Line: 564:576

Comment:
`withIdempotency()` does `await store.has(key)` and then `await store.set(key, ttlMs)`. With two concurrent calls for the same key, both can observe `has=false` before either `set()` runs, causing double execution and defeating deduplication under load. This needs an atomic “set-if-absent/claim” operation in the store API (or a synchronous critical section in the in-memory store).

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/health/channel-health.ts`**
`createChannelHealthRegistry().register()` overwrites an existing provider but doesn’t call `stopMonitoring()` on the old one. If the previous provider had started an interval, it will keep running and updating/logging after being replaced. Consider calling `providers.get(provider.channel)?.stopMonitoring?.()` before `providers.set(...)`.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/health/channel-health.ts
Line: 81:86

Comment:
`createChannelHealthRegistry().register()` overwrites an existing provider but doesn’t call `stopMonitoring()` on the old one. If the previous provider had started an interval, it will keep running and updating/logging after being replaced. Consider calling `providers.get(provider.channel)?.stopMonitoring?.()` before `providers.set(...)`.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/health/channel-health.ts`**
`heartbeatAll()` fabricates a synthetic `ChannelHealth` on exceptions with `consecutiveFailures: 1` and `lastHeartbeat: null`, which discards any cached state from `provider.getStatus()` (e.g., a long-failing channel will still report `1`). Consider merging with `provider.getStatus()` (incrementing `consecutiveFailures`, preserving `lastHeartbeat`) so summary/alerts remain accurate.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/health/channel-health.ts
Line: 107:126

Comment:
`heartbeatAll()` fabricates a synthetic `ChannelHealth` on exceptions with `consecutiveFailures: 1` and `lastHeartbeat: null`, which discards any cached state from `provider.getStatus()` (e.g., a long-failing channel will still report `1`). Consider merging with `provider.getStatus()` (incrementing `consecutiveFailures`, preserving `lastHeartbeat`) so summary/alerts remain accurate.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/streaming/stream-response.ts`**
`scheduleUpdate()` overwrites `state.pendingUpdate` on every chunk and only schedules a single timer. Under high-frequency `onChunk()` calls, intermediate updates are dropped (latest-only behavior). If callers expect incremental streaming, consider queueing deltas / forcing at least one send per interval, or explicitly documenting that updates are coalesced to the most recent state.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/streaming/stream-response.ts
Line: 1359:1364

Comment:
`scheduleUpdate()` overwrites `state.pendingUpdate` on every chunk and only schedules a single timer. Under high-frequency `onChunk()` calls, intermediate updates are dropped (latest-only behavior). If callers expect incremental streaming, consider queueing deltas / forcing at least one send per interval, or explicitly documenting that updates are coalesced to the most recent state.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>

---

**`src/channels/streaming/stream-response.ts`**
`onComplete()` clears `updateTimer` but never flushes `pendingUpdate` before calling `sendFinal(state.currentText)`. If completion happens during the throttle window, the last chunk text can be stuck in `pendingUpdate` and never sent, leaving `sendFinal` stale/incomplete. Consider flushing pending updates (or preferring `pendingUpdate ?? currentText`) before sending the final message.

<details><summary>Prompt To Fix With AI</summary>

`````markdown
This is a comment left during a code review.
Path: src/channels/streaming/stream-response.ts
Line: 1394:1405

Comment:
`onComplete()` clears `updateTimer` but never flushes `pendingUpdate` before calling `sendFinal(state.currentText)`. If completion happens during the throttle window, the last chunk text can be stuck in `pendingUpdate` and never sent, leaving `sendFinal` stale/incomplete. Consider flushing pending updates (or preferring `pendingUpdate ?? currentText`) before sending the final message.

How can I resolve this? If you propose a fix, please make it concise.
`````
</details>
</details>


## Stats

- **Size:** huge (1532+, 0-, 10 files)
- **Age:** 0 days
- **Last activity:** 2026-02-03

## Links

- Fixes: (none detected)

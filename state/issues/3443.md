---
number: 3443
title: "[Bug]: Message ordering conflict error when using custom Moonshot/Kimi provider"
author: justinfinnn
created: 2026-01-28T16:24:50Z
updated: 2026-02-02T05:07:15Z
labels: ["bug"]
assignees: []
comments_count: 8
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/3443
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Description

When switching to Moonshot models (Kimi K2.5), I consistently get "Message ordering conflict - please try again. If this persists, use /new to start a fresh session." The error persists even after:
- Gateway restart
- Session file cleanup
- `/new` command

The issue only occurs with Moonshot models; Anthropic models work fine.

## Config (sanitized)

```json
"models": {
  "providers": {
    "moonshot": {
      "baseUrl": "https://api.moonshot.ai/v1",
      "apiKey": "sk-***REDACTED***",
      "api": "openai-completions",
      "models": [
        {
          "id": "kimi-k2.5",
          "name": "Kimi K2.5",
          "reasoning": true,
          "input": ["text", "image"],
          "contextWindow": 262144,
          "maxTokens": 8192
        }
      ]
    }
  }
}
```

## Environment

- Clawdbot version: 2026.1.24-3
- OS: macOS (Darwin 25.2.0 arm64)
- Node: v22.22.0
- Channel: Discord

## Steps to Reproduce

1. Configure Moonshot provider as shown above
2. Add `moonshot/kimi-k2.5` to `agents.defaults.models` with an alias
3. Switch to the model using `/model kimi`
4. Send any message
5. Receive "Message ordering conflict" error

## Expected Behavior

Model should respond normally like Anthropic models do.

## Additional Context

The gateway log shows the embedded run starting and completing successfully (793ms), but the error message is delivered to the user anyway. The error seems to occur in session state handling rather than the API call itself.

## Comments

### @zouzhenglu (2026-01-31)

I also got this bug. I am use custom model , aliyun bailian,sisiliconflow . 
`"agents": {
    "defaults": {
      "model": {
        "primary": "siliconflow/deepseek-ai/DeepSeek-V3.2"
      },
      "models": {
        "bailian/kimi-k2-thinking": {},
        "bailian/aliyun/glm-4.7": {},
        "bailian/aliyun/MiniMax-M2.1": {},
        "siliconflow/deepseek-ai/DeepSeek-V3.2": {},
        "siliconflow/Pro/deepseek-ai/DeepSeek-V3.2": {},
        "siliconflow/Pro/MiniMaxAI/MiniMax-M2.1": {},
        "google/gemini-flash-lite-latest": {},
        "google/gemini-flash-latest": {},
        "google/gemini-2.5-flash-lite": {},
        "google/gemini-2.5-flash": {}
      },
    }
  },`
environment
version：openclaw@2026.1.29
OS：Windows11
Node:22.22.0
Channel:telegram

### @owainharris (2026-02-01)

Seems to happen when using moonshot as the provider and having **"reasoning": "true".**
Switching reasoning to false resolved it - though results in degraded performance. 
        
`{
  "id": "kimi-k2.5",
  "name": "Kimi K2.5 (Latest Multimodal)",
  "reasoning": false,
  "input": [
    "text",
    "image"
  ],
  "cost": {
    "input": 0,
    "output": 0,
    "cacheRead": 0,
    "cacheWrite": 0
  },
  "contextWindow": 256000,
  "maxTokens": 8192
}`

### @Gyanano (2026-02-01)

I found a workaround for this issue. The bug seems to be triggered when using custom provider names (like deepseek, openrouter, etc.) with reasoning: true.
However, if you use anthropic as the provider name (which is a recognized built-in provider), the bug doesn't occur.

### Solution:

If your model provider supports the Anthropic API format (like Deepseek does via https://api.deepseek.com/anthropic), you can configure it under the anthropic
provider with a custom baseUrl:
```
{
  "models": {
    "providers": {
      "anthropic": {
        "baseUrl": "https://api.deepseek.com/anthropic",
        "apiKey": "<your-api-key>",
        "auth": "api-key",
        "api": "anthropic-messages",
        "models": [
          {
            "id": "deepseek-reasoner",
            "name": "Deepseek Reasoner",
            "reasoning": true,
            "input": ["text"],
            "contextWindow": 128000,
            "maxTokens": 8192
          }
        ]
      }
    }
  }
}
```
Then reference the model as anthropic/deepseek-reasoner in your agent config.

### Why this works:

The "Message ordering conflict" error appears to be related to how OpenClaw
handles the reasoning flag for non-built-in provider names. By using anthropic as
  the provider name (even though it points to a different API endpoint), the
internal logic correctly processes the thinking/reasoning blocks.
This is obviously a workaround, not a proper fix. The underlying issue should
still be addressed so that custom providers can use `reasoning: true` without this
error.

### @BB9z (2026-02-01)

This is not a bug. Encountering this issue is a configuration problem. You can refer to the configuration below for modifications.

```json
{
  "models": {
    "mode": "merge",
    "providers": {
      "moonshot": {
        // api.moonshot.ai OR api.moonshot.cn
        "baseUrl": "https://api.moonshot.cn/anthropic",
        "apiKey": "sk-...",
        "api": "anthropic-messages",
        "models": [
          {
            "id": "kimi-k2-0905-preview",
            "name": "Kimi K2 0905 Preview",
            "reasoning": true,
            "input": [
              "text",
              "image"
            ],
            "cost": {
              "input": 4.0,
              "output": 16.0,
              "cacheRead": 1.0,
              "cacheWrite": 1.0
            },
            "contextWindow": 262144,
            "maxTokens": 26214
          },
          {
            "id": "kimi-k2.5",
            "name": "Kimi K2.5",
            "reasoning": true,
            "input": [
              "text",
              "image"
            ],
            "cost": {
              "input": 4.0,
              "output": 21.0,
              "cacheRead": 0.7,
              "cacheWrite": 0.7
            },
            "contextWindow": 262144,
            "maxTokens": 26214
          }
        ]
      }
    }
  },
  ...
}
```

### @Mike-Solar (2026-02-01)

This is still a bug. It seems that it only happens when using OpenAI-compatible API and enables thinking. 

### @justinfinnn (2026-02-02)

Still a bug for kimi k2.5

Config set to:
`"api": "anthropic-messages",` --> `Message ordering conflict - please try again. If this persists, use /new to start a fresh session.`

Config set to:
`"api": "anthropic-messages",` --> `404 没找到对象`

### @wuzitingx-nft (2026-02-02)

I used  "baseUrl": "https://api.moonshot.cn/anthropic" and turned on reasoning. While the basic conversation is good to go, but when it triggers thinking, it raise the error of 
"LLM request rejected: error, status code: 400, message: thinking is enabled but reasoning_content is missing in assistant tool call message at index 12"
is this error content related to this issue? I am not an expert and got no idea

### @Gyanano (2026-02-02)

> I used  "baseUrl": "https://api.moonshot.cn/anthropic" and turned on reasoning. While the basic conversation is good to go, but when it triggers thinking, it raise the error of 
> "LLM request rejected: error, status code: 400, message: thinking is enabled but reasoning_content is missing in assistant tool call message at index 12"
> is this error content related to this issue? I am not an expert and got no idea

Perhaps the model you are using is a non-thinking model.
For details, please refer to https://platform.moonshot.cn/docs/guide/agent-support


## Links

- None detected yet

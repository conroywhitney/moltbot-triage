---
number: 7681
title: "[Bug]: /status and session_status token counter underreports actual context usage — excludes system prompt, tools, and injected files"
author: agent-derek
created: 2026-02-03T03:32:24Z
updated: 2026-02-03T03:32:24Z
labels: []
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/7681
duplicate_of: null
related_issues: [1078,2868,6012]
blocks: []
blocked_by: []
---

## Description

## Summary

The token counter displayed by `/status` and the `session_status` tool significantly underreports actual token usage. The displayed value appears to show only conversation message tokens, **excluding**:

- System prompt (tool list, skill descriptions, self-update instructions, runtime metadata)
- Injected workspace/bootstrap files (AGENTS.md, SOUL.md, TOOLS.md, IDENTITY.md, USER.md, HEARTBEAT.md, MEMORY.md)
- Provider safety headers and wrappers

This creates a **~200k token gap** between what the counter shows and what is actually being sent to the API on each request.

## Steps to Reproduce

1. Start a session with significant workspace files injected (multiple large .md files, many skills, many tools)
2. Send a few messages
3. Run `/status` or call `session_status`
4. Compare reported token count to actual `input_tokens` from API response (visible in debug logs or provider dashboard)
5. Observe: reported count is dramatically lower than actual

## Expected Behavior

The context usage counter should reflect the **total tokens sent per API request**, including:
- System prompt (all injected sections)
- Tool definitions
- Workspace/bootstrap files
- Conversation history
- Any other content in the request payload

This is what matters for context window management — users need to know how close they are to the model's actual limit.

## Actual Behavior

The counter appears to show only conversation-level tokens. With a large system prompt (which can easily be 50-100k+ tokens with workspace files and tools), the counter shows a fraction of actual usage.

## Code Analysis

In `dist/commands/agent/session-store.js`:
```javascript
next.totalTokens = promptTokens > 0 ? promptTokens : (usage.total ?? input);
```

Where `promptTokens = input + cacheRead + cacheWrite` from the API response. The Anthropic API's `input_tokens` field **should** include system prompt tokens, so `totalTokens` should be correct at the session store level.

However, in `dist/agents/tools/session-status-tool.js`, the status message is built with:
```javascript
includeTranscriptUsage: false
```

This means the tool relies entirely on `entry.totalTokens` from the session store, and never cross-checks against the transcript. If the session store value is stale or wasn't properly updated (e.g., different code paths for auto-reply vs TUI), the displayed count will be wrong.

Additionally, in `dist/auto-reply/status.js`, the fallback logic:
```javascript
let totalTokens = entry?.totalTokens ?? (entry?.inputTokens ?? 0) + (entry?.outputTokens ?? 0);
```

The fallback uses `inputTokens` which is set to `usage.input` (non-cached input only), potentially missing `cacheRead` and `cacheWrite` tokens.

## Related Issues

- #6012 — `contextTokens` shows model maximum instead of actual (denominator bug; this issue is about the numerator)
- #1078 — TUI counter not refreshing after runs (display refresh bug, closed)
- #2868 — Unexpected high token consumption (observes the discrepancy from the API cost side)

## Environment

- OpenClaw latest (npm)
- macOS 14.x (arm64)
- Model: anthropic/claude-opus-4-5
- Auth: OAuth
- Large workspace: AGENTS.md (~10k chars), SOUL.md, TOOLS.md, IDENTITY.md, USER.md, HEARTBEAT.md, MEMORY.md — all injected into system prompt
- 25+ skills listed (metadata injected)
- 20+ tools defined

## Proposed Fix

1. **Always use transcript-based usage in `session_status`**: Set `includeTranscriptUsage: true` (or derive it from the last API response in the session log)
2. **Ensure all code paths update session store**: Verify that auto-reply, Slack, Telegram, and other message paths all call `updateSessionStoreAfterAgentRun` with correct usage data
3. **Add `/context` data to status**: Consider showing a breakdown: system prompt tokens, tool tokens, conversation tokens, total
4. **Fix the fallback formula**: The fallback `inputTokens + outputTokens` should use `totalTokens` (which includes cache tokens) instead of raw `inputTokens`

## Comments


## Links

- None detected yet

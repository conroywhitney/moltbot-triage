---
number: 3181
title: "[Bug]: Runaway heartbeat loop triggers excessive model calls + retries (high CPU / cost)"
author: Valleyaapo
created: 2026-01-28T06:51:31Z
updated: 2026-01-30T02:10:08Z
labels: ["bug"]
assignees: []
comments_count: 2
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/3181
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

Observed a runaway loop where repeated inbound “heartbeat poll” messages triggered continuous processing and embedded agent runs. Combined with outbound Telegram sendMessage failures and embedded-run timeouts, this created a retry storm that drove high CPU usage and excessive codex traffic.

Impact

• High CPU load on host for an extended period.
• Excessive LLM invocations (cost + rate-limit pressure).
• Delayed / degraded responsiveness on Telegram due to failures/backlog.
• Rapid log growth in gateway error logs.

### Symptoms:
From gateway logs:

• Repeated embedded agent fallback:  • unsupported thinking level for openai-codex/gpt-5.2; retrying with low
• Repeated embedded run timeouts:  • embedded run timeout … timeoutMs=600000
  • Profile openai-codex:codex-cli timed out (possible rate limit). Trying next account...
• Repeated Telegram send failures:  • [heartbeat] failed: Network request for 'sendMessage' failed!

Also observed: frequent heartbeat: started entries clustered in time.
Root Cause:

1. Repeated trigger input: identical “heartbeat poll” messages were injected repeatedly (same content), each triggering a heartbeat handler response and/or an LLM-backed processing path.
2. Retry amplification: intermittent Telegram sendMessage failures and embedded-agent timeouts caused repeated retries; with the trigger repeating, load compounded.
Contributing Factors

• No deduplication/idempotency for identical heartbeat poll payloads.
• Insufficient rate limiting/backoff for heartbeat processing and Telegram send failures.
• “Unsupported thinking level” fallback appears to happen repeatedly rather than being normalized once.
• Long embedded run timeout (10 minutes) increases overlap when retriggered frequently.
### Expected Behavior
• Heartbeat polls should be handled deterministically without invoking the model.
• Identical heartbeat poll messages should be deduped within a time window.
• Network send failures should back off with jitter and stop after a capped number of retries.
• The system should detect and break infinite loops / repeated triggers.
### Proposed Fixes

1) Dedupe + rate-limit heartbeat polls

• Add per-chat/session dedupe for identical heartbeat poll messages (e.g., ignore duplicates for 10–60 minutes).
• Add a hard rate limit: max 1 heartbeat response per N minutes per chat.
2) Prevent LLM invocation for heartbeat ack

• Ensure heartbeat poll handling is a non-LLM code path (pure deterministic response), unless explicitly configured otherwise.
3) Backoff + circuit breakers for Telegram send failures

• Exponential backoff with jitter on sendMessage failures.
• Cap retries and add a circuit breaker to temporarily disable heartbeat sends after repeated failures.
4) Reduce retry churn for thinking-level mismatch

• Pre-normalize “thinking level” once per model/profile and cache it.
• If unsupported, set to low without repeated retries/log spam.
5) Concurrency limits

• Add per-session/global concurrency limits for embedded agent runs to prevent pile-ups.
Acceptance Criteria

• Replaying the same heartbeat poll message repeatedly does not trigger repeated LLM runs.
• Under simulated Telegram send failures, retry rate stays bounded (backoff works) and CPU remains stable.
• Logs show at most one “thinking level fallback” per process start or per profile.
• Add automated test(s) covering heartbeat dedupe and failure backoff behavior.
### Notes:
redacted logs
```
[agent/embedded] Profile openai-codex:codex-cli timed out (possible rate limit). Trying next account...
[agent/embedded] unsupported thinking level for openai-codex/gpt-5.2; retrying with low
[agent/embedded] embedded run timeout: runId=xxx sessionId=xxx timeoutMs=600000
[agent/embedded] Profile openai-codex:codex-cli timed out (possible rate limit). Trying next account...
[agent/embedded] unsupported thinking level for openai-codex/gpt-5.2; retrying with low
[ws] unauthorized conn=xxx remote=127.0.0.1 client=cli probe vdev
[ws] closed before connect conn=xxxx remote=127.0.0.1 fwd=n/a origin=n/a host=127.0.0.1:18789 ua=n/a code=1008 reason=connect failed
[ws] unauthorized conn=xxx remote=127.0.0.1 client=cli probe vdev
```

## Comments

### @Glucksberg (2026-01-28)

Related heartbeat issues that may share causes:

**Related Issues:**
- #3445 - Heartbeat causes crash loop with AbortError
- #3389 - HEARTBEAT.md not working
- #2935 - Heartbeat stops firing after context compression
- #2804 - System events trigger rapid heartbeat re-runs

**PRs that may help:**
- #3420 - fix: skip heartbeat wake for subagent exec completions
- #3396 - Config: gateway.unhandledRejections (warn|exit)

These heartbeat issues seem to involve either over-triggering or complete failure - the extremes of the same system.

### @miguelmanlyx (2026-01-30)

@Valleyaapo 

 Hi, that looks like a Cost / Tokens issue. Have you tried running `npx ai-patch doctor` to sanity-check token usage and common causes of sudden cost spikes?



## Links

- None detected yet

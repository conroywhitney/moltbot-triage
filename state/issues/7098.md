---
number: 7098
title: "[Bug]: OpenClaw 2026.1.30 - Multiple Critical Issues"
author: Paulie-Moo
created: 2026-02-02T11:37:00Z
updated: 2026-02-02T11:37:00Z
labels: ["bug"]
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/7098
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

# Bug Report: OpenClaw 2026.1.30 - Multiple Critical Issues

## Environment
- **OS**: macOS 26.2 (Darwin 25.2.0, arm64)
- **Node**: v25.5.0
- **OpenClaw Version**: 2026.1.30 (76b5208)
- **Previous Version**: clawdbot (upgraded via npm)
- **LM Studio**: Running on localhost:1234

---

## Issue 1: Missing Template Error After Upgrade [RESOLVED]

**Error:**
```
run error: Error: Missing workspace template: AGENTS.md
(/opt/homebrew/lib/node_modules/clawdbot/docs/reference/templates/AGENTS.md)
```

**Root Cause:** Old `clawdbot-gateway` process persisted after npm upgrade with cached paths pointing to the old `/opt/homebrew/lib/node_modules/clawdbot/` directory.

**Resolution:**
1. Kill old gateway: `pkill -f clawdbot-gateway`
2. Clean npm cache: `npm cache clean --force`
3. Reinstall: `npm uninstall -g openclaw && npm install -g openclaw`
4. Reinstall launch agent: `openclaw gateway install`
5. Remove old launch agent: `rm ~/Library/LaunchAgents/com.clawdbot.gateway.plist`

**Suggestion:** Upgrade process should warn users to restart gateway or auto-detect stale processes.

---

## Issue 2: External API Requests Timeout [UNRESOLVED]

**Symptoms:**
- All OpenRouter/Anthropic API requests timeout after ~32 seconds
- Error: `FailoverError: Request timed out.`
- Providers enter cooldown state, preventing further requests

**Key Finding:** Direct API calls work perfectly:

```bash
# Works (8 seconds):
curl https://openrouter.ai/api/v1/chat/completions \
  -H "Authorization: Bearer $KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"moonshotai/kimi-k2.5","messages":[{"role":"user","content":"hi"}]}'

# Works (2 seconds):
node -e "fetch('https://openrouter.ai/api/v1/chat/completions', {
  method: 'POST',
  headers: {'Authorization': 'Bearer $KEY', 'Content-Type': 'application/json'},
  body: JSON.stringify({model: 'moonshotai/kimi-k2.5', messages: [{role: 'user', content: 'hi'}]})
}).then(r => r.json()).then(console.log)"

# Fails (32 second timeout):
openclaw tui --message "hello"
# Error: All models failed: openrouter/moonshotai/kimi-k2.5: Request timed out.
```

**Affected Models:**
- `openrouter/moonshotai/kimi-k2.5`
- `anthropic/claude-opus-4-5-20251101`
- `anthropic/claude-3-5-sonnet-20241022`

**Hypothesis:** Something in openclaw's HTTP request handling differs from standard Node.js fetch (streaming, headers, body construction, or internal timeout configuration).

---

## Issue 3: LM Studio Local Models Return No Output [UNRESOLVED]

**Symptoms:**
- Local models connect successfully (no timeout)
- Task completes normally (~19 seconds)
- TUI shows "(no output)" despite valid response from model

**Key Finding:** Direct LM Studio API works:

```bash
# Works:
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"qwen/qwen3-4b-2507","messages":[{"role":"user","content":"say hello"}],"max_tokens":50}'
# Returns: {"choices":[{"message":{"content":"Hello! How can I assist you today?"}}]}

# Fails (no output displayed):
openclaw tui --session "test" --message "hello"
# Shows: "(no output)"
```

**Logs show task completes successfully:**
```
embedded run start: provider=lmstudio model=qwen/qwen3-4b-2507 thinking=off
lane task done: lane=session:agent:main:test durationMs=19534 active=0 queued=0
```

**Config:** Using `"api": "openai-responses"` for the LM Studio provider.

**Note:** Some models in LM Studio also have issues:
- `qwen/qwen3-vl-8b` - crashes with "The model has crashed without additional information"
- `openai/gpt-oss-20b` - returns malformed content (`<|channel|>final` instead of actual text)
- `qwen/qwen3-4b-2507` - works directly via curl but not through openclaw

---

## Additional Technical Details

### Cooldown State File
Location: `~/.openclaw/agents/main/agent/auth-profiles.json`

The cooldown state is stored in `usageStats.*.cooldownUntil` as a Unix timestamp. Manual clearing requires editing this file and removing the `cooldownUntil`, `lastFailureAt`, and resetting `errorCount` to 0.

### Log Files
- Gateway logs: `/tmp/openclaw/openclaw-2026-02-02.log`
- Gateway stderr: `~/.openclaw/logs/gateway.err.log`
- Gateway stdout: `~/.openclaw/logs/gateway.log`

### Background Fetch Errors
Repeated "Non-fatal unhandled rejection: TypeError: fetch failed" errors appear in logs. These seem unrelated to the main API call issues and may be from Tailscale/Bonjour background tasks.

---

## Workaround

Currently none available - both external APIs and local LM Studio fail to return responses in openclaw 2026.1.30.

---

## Steps to Reproduce

### Issue 2 (External API Timeout):
1. Fresh install of openclaw 2026.1.30
2. Configure OpenRouter with valid API key
3. Run `openclaw tui --message "hello"`
4. Wait 32 seconds for timeout

### Issue 3 (Local Model No Output):
1. Start LM Studio with a model loaded (e.g., qwen3-4b-2507)
2. Configure openclaw with lmstudio provider pointing to localhost:1234
3. Run `openclaw tui --message "hello"`
4. Observe "(no output)" despite successful task completion

---

## Expected vs Actual Behavior

| Scenario | Expected | Actual |
|----------|----------|--------|
| External API call | Response in <10s | Timeout after 32s |
| Local LM Studio call | Response displayed | "(no output)" shown |
| Direct curl/fetch | Works | Works |

---

*Report generated: 2026-02-02*

## Comments


## Links

- None detected yet

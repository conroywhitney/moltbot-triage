---
number: 6647
title: "[Bug]: speed up performance: Tool Result Session Bloat Fix"
author: Lennie
created: 2026-02-01T22:33:07Z
updated: 2026-02-01T22:33:07Z
labels: ["bug"]
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/6647
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

LLM request latency

## Actual behavior

1. Scan all skill directories (file system I/O)
2. Parse all SKILL.md files (YAML frontmatter + markdown)
3. Check binary requirements (`hasBinary()` - PATH scanning)
4. Filter through eligibility rules
5. Format into system prompt
6. Create all tool instances
7. Filter through 7+ policy layers

All of this happens even though skills/tools rarely change between requests.

## Proposed solution blueprint

# Skill & Tool Caching with File Watching

> **Note:** This addresses request latency. For reducing token usage via dynamic tool discovery, see [Dynamic Tool Discovery](./dynamic-tool-discovery.md).

## Problem

Current behavior (on every request):
1. Scan all skill directories (file system I/O)
2. Parse all SKILL.md files (YAML frontmatter + markdown)
3. Check binary requirements (`hasBinary()` - PATH scanning)
4. Filter through eligibility rules
5. Format into system prompt
6. Create all tool instances
7. Filter through 7+ policy layers

All of this happens even though skills/tools rarely change between requests.

## Solution: Cached Skill Registry with File Watching

```
┌─────────────────────────────────────────────────────────────────┐
│                     File Watcher Cache                          │
├─────────────────────────────────────────────────────────────────┤
│  SkillCache:                                                    │
│    - skills: SkillEntry[] (filtered & ready)                    │
│    - prompt: string (pre-formatted)                             │
│    - toolRegistry: Map<string, ToolFactory>                     │
│    - mtime: Map<string, number> (file modification times)       │
│    - watchers: FSWatcher[]                                      │
└──────────────────────┬──────────────────────────────────────────┘
                       │
    ┌──────────────────┼──────────────────┐
    │                  │                  │
    ▼                  ▼                  ▼
┌────────┐      ┌──────────┐      ┌──────────┐
│Request │      │File      │      │Binary     │
│Comes In │      │Changes   │      │Installed  │
└───┬────┘      └────┬─────┘      └────┬─────┘
    │                │                 │
    ▼                ▼                 ▼
┌──────────────────────────────────────────────────┐
│  Cache Hit?                                       │
│  - Files unchanged? → Return cached prompt        │
│  - Files changed?   → Rebuild cache               │
│  - Binary added?    → Invalidate & rebuild        │
└──────────────────────────────────────────────────┘
```

## Implementation

### New File: `src/agents/skills/cache.ts`

```typescript
export type SkillCache = {
  // Cached data
  entries: SkillEntry[];
  snapshot: SkillSnapshot;
  prompt: string;
  
  // Cache metadata
  fileHashes: Map<string, string>;  // file path → content hash
  binaryState: Map<string, boolean>; // binary name → was found
  configHash: string;               // hash of relevant config
  
  // Watchers
  watchers: FSWatcher[];
  invalidated: boolean;
};

class SkillCacheManager {
  private cache: SkillCache | null = null;
  private workspaceDir: string;
  
  constructor(workspaceDir: string) {
    this.workspaceDir = workspaceDir;
  }
  
  async getSkillsPrompt(opts: {
    config?: OpenClawConfig;
    eligibility?: SkillEligibilityContext;
  }): Promise<string> {
    // Check if cache is valid
    if (this.cache && !this.cache.invalidated && this.isCacheValid(opts)) {
      return this.cache.prompt;
    }
    
    // Rebuild cache
    await this.rebuildCache(opts);
    return this.cache!.prompt;
  }
  
  private isCacheValid(opts: {
    config?: OpenClawConfig;
    eligibility?: SkillEligibilityContext;
  }): boolean {
    if (!this.cache) return false;
    
    // Check if any files changed
    for (const [filePath, hash] of this.cache.fileHashes) {
      const currentHash = computeFileHash(filePath);
      if (currentHash !== hash) return false;
    }
    
    // Check if any binary availability changed
    for (const [bin, wasFound] of this.cache.binaryState) {
      const nowFound = hasBinary(bin);
      if (nowFound !== wasFound) return false;
    }
    
    // Check if config changed
    const currentConfigHash = hashConfig(opts.config);
    if (currentConfigHash !== this.cache.configHash) return false;
    
    return true;
  }
  
  private async rebuildCache(opts: {
    config?: OpenClawConfig;
    eligibility?: SkillEligibilityContext;
  }): Promise<void> {
    // Load and filter skills
    const entries = loadSkillEntries(this.workspaceDir, opts);
    const eligible = filterSkillEntries(entries, opts.config, undefined, opts.eligibility);
    
    // Build prompt
    const promptEntries = eligible.filter(
      (entry) => entry.invocation?.disableModelInvocation !== true
    );
    const prompt = formatSkillsForPrompt(promptEntries.map((e) => e.skill));
    
    // Compute file hashes
    const fileHashes = new Map<string, string>();
    for (const entry of entries) {
      const hash = await computeFileHash(entry.source);
      fileHashes.set(entry.source, hash);
    }
    
    // Record binary state
    const binaryState = new Map<string, boolean>();
    for (const entry of eligible) {
      const bins = entry.metadata?.requires?.bins ?? [];
      for (const bin of bins) {
        if (!binaryState.has(bin)) {
          binaryState.set(bin, hasBinary(bin));
        }
      }
    }
    
    // Set up watchers
    this.setupWatchers(entries);
    
    this.cache = {
      entries: eligible,
      snapshot: {
        prompt,
        skills: eligible.map((e) => ({ name: e.skill.name })),
        version: Date.now(),
      },
      prompt,
      fileHashes,
      binaryState,
      configHash: hashConfig(opts.config),
      watchers: [],
      invalidated: false,
    };
  }
  
  private setupWatchers(entries: SkillEntry[]): void {
    // Clean up old watchers
    this.cache?.watchers.forEach((w) => w.close());
    
    const dirsToWatch = new Set<string>();
    for (const entry of entries) {
      dirsToWatch.add(path.dirname(entry.source));
    }
    
    const watchers: FSWatcher[] = [];
    for (const dir of dirsToWatch) {
      const watcher = watch(dir, { recursive: true }, (eventType, filename) => {
        if (filename?.endsWith('.md')) {
          this.cache!.invalidated = true;
        }
      });
      watchers.push(watcher);
    }
    
    if (this.cache) {
      this.cache.watchers = watchers;
    }
  }
  
  dispose(): void {
    this.cache?.watchers.forEach((w) => w.close());
    this.cache = null;
  }
}
```

### Tool Caching: `src/agents/tools/tool-cache.ts`

Similar pattern for tools:

```typescript
export type ToolCache = {
  // Cached tool factories (not instances)
  coreToolFactories: Map<string, ToolFactory>;
  pluginToolFactories: Map<string, ToolFactory>;
  
  // Pre-computed schemas
  toolSchemas: Map<string, unknown>;
  
  // Cache metadata  
  configHash: string;
  pluginRegistryHash: string;
  invalidated: boolean;
};

class ToolCacheManager {
  private cache: ToolCache | null = null;
  
  getTools(opts: CreateToolsOptions): AnyAgentTool[] {
    if (this.cache?.invalidated || !this.isValid(opts)) {
      this.rebuildCache(opts);
    }
    
    // Create tool instances from cached factories
    // (still need instances per-request for state, but factories are cached)
    const tools: AnyAgentTool[] = [];
    for (const [name, factory] of this.cache!.coreToolFactories) {
      if (this.isToolAllowed(name, opts)) {
        tools.push(factory(opts));
      }
    }
    
    return tools;
  }
  
  private rebuildCache(opts: CreateToolsOptions): void {
    // Register tool factories (cheap) not instances (expensive)
    const coreFactories = new Map<string, ToolFactory>();
    
    // Instead of: tools.push(createBrowserTool({...}))
    // Do: coreFactories.set("browser", (opts) => createBrowserTool(opts))
    
    this.cache = {
      coreToolFactories: coreFactories,
      pluginToolFactories: loadPluginToolFactories(),
      toolSchemas: precomputeSchemas(),
      configHash: hashToolConfig(opts.config),
      pluginRegistryHash: hashPluginRegistry(),
      invalidated: false,
    };
  }
}
```

## Key Optimizations

### 1. Factory Pattern (Not Instance Caching)

**Don't cache:** Tool instances (they may have request-specific state)
**Do cache:** Tool factories + schemas

```typescript
// Cached
const browserFactory = (opts) => createBrowserTool(opts);
const browserSchema = { /* schema */ };

// Per-request instantiation
const browserTool = browserFactory(currentRequestOpts);
```

### 2. Binary State Polling (Not Checking Every Request)

```typescript
// Instead of hasBinary() for every skill on every request:
// Check once at cache build time
// Re-check periodically (every 30s) or on file changes
setInterval(() => {
  if (binaryAvailabilityChanged()) {
    cache.invalidated = true;
  }
}, 30000);
```

### 3. Config-Aware Caching

```typescript
// Only invalidate if relevant config changes
const RELEVANT_CONFIG_KEYS = [
  'skills.allowBundled',
  'skills.install',
  'agents.*.tools',
  'tools.allow',
  'tools.deny',
];

function hashConfig(config: OpenClawConfig): string {
  const relevant = pick(config, RELEVANT_CONFIG_KEYS);
  return hash(relevant);
}
```

## Integration Points

### Modify: `src/agents/skills/workspace.ts`

```typescript
// Add cache manager singleton per workspace
const cacheManagers = new Map<string, SkillCacheManager>();

export function getSkillsPrompt(workspaceDir: string, opts: {...}): string {
  let manager = cacheManagers.get(workspaceDir);
  if (!manager) {
    manager = new SkillCacheManager(workspaceDir);
    cacheManagers.set(workspaceDir, manager);
  }
  return manager.getSkillsPrompt(opts);
}
```

### Modify: `src/agents/pi-tools.ts`

```typescript
// Use cached tool factories
const toolCache = new ToolCacheManager();

export function createOpenClawCodingTools(options?: {...}): AnyAgentTool[] {
  return toolCache.getTools(options);
}
```

## Performance Impact

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Skill loading | 40+ file reads | 0 (cache hit) | **∞x** |
| Binary checks | 40+ PATH scans | 0 (cache hit) | **∞x** |
| Prompt formatting | Full reformat | Return string | **∞x** |
| Tool creation | 30+ instantiations | 30 factory calls | ~10x |
| Cache rebuild | N/A | ~200ms | Rare |

## Trade-offs

| Aspect | File Watcher Cache | Dynamic Discovery |
|--------|-------------------|-------------------|
| **Complexity** | Medium | High |
| **Token usage** | Same (all skills in prompt) | Much lower |
| **Request latency** | Much improved | Best |
| **Memory usage** | Higher (cached data) | Lower |
| **Startup time** | Slower (initial cache build) | Faster |
| **Scalability** | Limited (still O(n) skills) | Unbounded |

## Recommendation

**Implement file watcher caching first** because:
1. Easier to implement (~1 week vs ~1 month)
2. Addresses the "slowness" complaint significantly
3. Can be done incrementally (skills first, then tools)
4. Provides foundation for dynamic discovery later

**Then consider dynamic discovery** if:
- Token usage becomes the bottleneck
- You have 100+ skills/tools
- You want sub-agent isolation of tools

## Migration Path

1. **Phase 1**: Skill caching with file watching
2. **Phase 2**: Tool factory caching
3. **Phase 3**: (Optional) Dynamic tool discovery on top of cached registry

## Comments


## Links

- None detected yet

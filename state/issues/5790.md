---
number: 5790
title: "Ollama/local models ignored â€” hard fallback to Anthropic provider in Gateway and CLI (v2026.1.30)"
author: margrimm9999
created: 2026-02-01T00:02:23Z
updated: 2026-02-02T00:17:42Z
labels: ["bug"]
assignees: []
comments_count: 0
reactions_total: 3
url: https://github.com/openclaw/openclaw/issues/5790
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

**Version**: 2026.1.30 (76b5208)

**Issue**:
Setting local/Ollama model via `openclaw models set qwen2.5-coder:7b` results in logs always showing `agent model: anthropic/qwen2.5-coder:7b` (or full Anthropic fallback).

Messages in Control UI fail silently (no response/file creation) because no Anthropic API key is configured.

Env vars (LLM_PROVIDER=ollama, OLLAMA_BASE_URL, OLLAMA_MODEL) do not override.

`models add` rejects --provider / --baseUrl flags.

Config keys like "llm", "models.default", "agents.main", "gateway.bind" trigger validation errors and are removed by doctor --fix.

**Reproduction**:
1. ollama pull qwen2.5-coder:7b
2. ollama run qwen2.5-coder:7b
3. openclaw models set qwen2.5-coder:7b
4. openclaw gateway --force --allow-unconfigured --token test
5. Logs show anthropic fallback.
6. UI chat messages get no response.

**Workaround**:
Direct Ollama curl or wrapper script works fine.

**Expected**:
Gateway/agent uses Ollama when set via CLI/config/env.

**Environment**:
macOS (M4 Pro, 24 GB RAM)
Ollama 0.15.2 (Metal)
Node.js v22.22.0
npm-installed OpenClaw

## Comments


## Links

- None detected yet

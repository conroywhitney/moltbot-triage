---
number: 7573
title: "Explicit audio models in tools.media.audio.models are ignored, falls back to active model (Claude)"
author: nezovskii
created: 2026-02-03T00:27:52Z
updated: 2026-02-03T00:27:52Z
labels: []
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/7573
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Description

Explicit audio transcription models configured in `tools.media.audio.models` or `tools.media.models` (with `capabilities: ["audio"]`) are ignored. Instead, audio is passed directly to the active chat model (Claude Opus 4.5 in our case), resulting in expensive multimodal transcription instead of using dedicated Whisper APIs.

## Steps to Reproduce

1. Configure Groq Whisper in `openclaw.json`:

```json
{
  "env": {
    "vars": {
      "GROQ_API_KEY": "gsk_..."
    }
  },
  "tools": {
    "media": {
      "models": [
        {
          "provider": "groq",
          "model": "whisper-large-v3-turbo",
          "capabilities": ["audio"]
        }
      ],
      "audio": {
        "enabled": true,
        "timeoutSeconds": 200,
        "models": [
          {
            "provider": "groq",
            "model": "whisper-large-v3-turbo"
          }
        ]
      }
    }
  }
}
```

2. Restart gateway
3. Send voice message via WhatsApp (no native transcription)
4. Check Groq Console - **no requests appear**
5. Check Anthropic Console - **requests appear** (audio processed by Claude)

## Expected Behavior

- Explicit `tools.media.audio.models` should be used for audio transcription
- Groq Whisper API should receive transcription requests
- Audio should NOT fall back to active model when explicit models are configured

## Actual Behavior

- Explicit models are ignored
- `resolveModelEntries()` appears to return entries, but they are not used
- Audio is passed to Claude as multimodal attachment
- Claude processes audio (expensive)

## Investigation Notes

- Verified Groq API key works: `curl https://api.groq.com/openai/v1/models -H "Authorization: Bearer $GROQ_API_KEY"` returns whisper models
- `groqProvider` is registered in `/src/media-understanding/providers/index.ts` with `capabilities: ["audio"]`
- `anthropicProvider` does NOT have `transcribeAudio` method, only `describeImage`
- Config validation passes (`valid: true`)
- Tested with both `audio.models` and shared `models` with `capabilities: ["audio"]` - same result

## Environment

- OpenClaw version: 2026.2.1
- OS: macOS (arm64)
- Active model: anthropic/claude-opus-4-5
- Channels tested: WhatsApp, Telegram

## Workaround

Currently none that preserves transcription. Disabling `audio.enabled` stops transcription entirely.

## Related Code

- `src/media-understanding/runner.ts` - `resolveModelEntries()`, `runCapability()`
- `src/media-understanding/resolve.ts` - `resolveModelEntries()`
- `src/media-understanding/providers/groq/index.ts` - Groq provider definition

## Comments


## Links

- None detected yet

---
number: 7482
title: "[Feature]: Intelligent Model Routing"
author: georgerous
created: 2026-02-02T21:46:45Z
updated: 2026-02-02T21:46:45Z
labels: ["enhancement"]
assignees: []
comments_count: 0
reactions_total: 1
url: https://github.com/openclaw/openclaw/issues/7482
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Feature Request: Intelligent Model Routing

### Summary
Add dynamic model selection capability that routes queries to different models based on content patterns, rather than using a static per-agent configuration.

### Motivation / Problem Statement

**Current State:**
- `agents.defaults.model` is static - one model for all queries
- Users either:
  - Waste tokens using expensive models (Pro) for simple queries ("what time is it?")
  - Get poor results using fast models (Flash) for complex tasks (code generation)

**Real-World Impact:**
We tested 7 models today with the same query ("weather tomorrow"):
- Gemini Flash: 7s, $0.01
- Gemini Pro: 9s, $0.03  
- MiniMax: 38s, $0.09

For simple factual queries, Flash is 22% faster and 66% cheaper than Pro.
For code tasks, Flash often fails where Kimi succeeds.

### Proposed Solution

Add new optional `modelRouting` configuration section:
agents:

defaults:

modelRouting:

enabled: true

defaultModel: "google/gemini-3-pro-preview"

rules:

# Code tasks -> Best coding model

- name: "code_tasks"

priority: 1

patterns:

- "(create|write|debug|fix).+(code|script|function)"

- "\.(py|js|ts|go|rs|cpp|c|java|html|css)\b"

- "(python|javascript|typescript).+(script|app)"

model: "kimi-coding/k2p5"

reasoning: true

tools: ["read", "write", "edit", "exec"]

# Web search -> Fast model for synthesis

- name: "web_search"

priority: 2

patterns:

- "(search|find|look up).+(online|internet|web|google)"

- "(what|who|when|where|how).+(happened|is|was|are)"

model: "google/gemini-2.0-flash"

tools: ["web_search", "web_fetch"]

# Simple queries -> Fastest model

- name: "simple_queries"

priority: 3

patterns:

- "^(what|which|how|where|when).+\?$"

- "(weather|time|temperature).+(today|tomorrow)"

- "translate.+to (english|spanish|french)"

model: "google/gemini-2.0-flash"

tools: [

# User override support

overrideKeywords:

- pattern: "\\buse\\s+(pro|gemini pro)\\b"

model: "google/gemini-3-pro-preview"

- pattern: "\\buse\\s+(flash|gemini flash)\\b"

model: "google/gemini-2.0-flash"

- pattern: "\\buse\\s+(kimi|reasoning)\\b"

model: "kimi-coding/k2p5"

reasoning: true

# Transparency settings

transparency: "minimal" # Options: never | always | minimal


### Key Features

1. **Pattern Matching**: Regex-based rules to classify queries
2. **Priority System**: First match wins (evaluated in order)
3. **Tool Scoping**: Different tools available per route (e.g., file tools for code)
4. **Override Support**: Users can force specific models via natural language
5. **Transparency Modes**:
   - `never`: Silent operation (default experience)
   - `always`: Show [Model] prefix on all responses
   - `minimal`: Show [Model] only when overridden or fallback used

### Backwards Compatibility

- **100% backwards compatible**
- New section is optional
- Default: `enabled: false` (current behavior)
- Existing `model` configs continue to work
- Can coexist with existing `fallbacks` array

### Use Cases

| Scenario | Without Routing | With Routing | Benefit |
|----------|----------------|--------------|---------|
| "What's the weather?" | Uses Pro ($0.03, 9s) | Uses Flash ($0.01, 7s) | 66% cheaper, 22% faster |
| "Debug this Python error" | Uses Pro (may fail) | Uses Kimi + reasoning (reliable) | Better quality |
| "Search for GPU prices" | Manual tool selection | Auto-routes with web_search tool | Better UX |
| User says "use Pro" | Ignored | Obeys override | User control |

### Implementation Approaches

**Option A: Config Extension (Preferred)**
Extend existing `agents.defaults.model` schema with `routing` subkey. Maintains config consistency.

**Option B: Plugin Hook**
Expose `preModelSelect` hook that plugins can implement. More flexible but requires plugin ecosystem.

**Option C: Pre-processor**
Implement as internal pre-processor before model selection. Cleanest but requires core changes.

### Alternative Considered

**Manual model specification per message**
Rejected: Too verbose for users
user: "/model kimi\ncreate a python script"


**Why rejected:** Requires users to learn commands. Automatic routing is seamless.

### Testing Evidence

We prototyped this today using `sessions_spawn` with different models:

**Test Results (Query: "weather tomorrow in Girona"):**
| Model | Response Time | Tokens | Cost | Result |
|-------|---------------|--------|------|--------|
| Gemini Flash | 7s | 8.6K | $0.008 | ✅ Accurate |
| Gemini Pro | 9s | 7.5K | $0.024 | ✅ Accurate |
| MiniMax M2.1 | 38s | 15.4K | $0.088 | ⚠️ Overthinking |

For simple factual queries, routing to Flash saves 22% time and 66% cost with equal accuracy.

**Code Task Test (Query: "create a TODO list app"):**
- Flash: Generated incomplete code, required 2 retries
- Kimi + reasoning: Generated complete app on first try

Routing code tasks to appropriate models improves reliability significantly.

### Willing to Contribute

- [x] I can help test this feature
- [x] I can provide detailed feedback on implementation
- [x] I can help document the feature
- [ ] I can contribute code (if guided)

### Additional Context

**Similar Features in Other Projects:**
- OpenRouter's "model fallbacks" (static, not pattern-based)
- LiteLLM's "router" (enterprise feature, complex config)
- This proposal aims for simplicity and OpenClaw's config style

**Potential Extensions (Future):**
- Learning mode: Track which routes succeed/fail and auto-adjust
- Cost budgets: Route to cheaper models when approaching limits
- Latency targets: Use faster models when user needs quick response

Supporting Evidence

Gemini Flash: ~7s
Gemini Pro: ~9s
MiniMax: ~38s

2. Cost Comparison
Simple calculation:

Assuming 100 queries/day:
- All Pro: 100 × $0.03 = $3.00/day = $90/month
- Routed (70% Flash, 30% Pro): (70×$0.01) + (30×$0.03) = $1.60/day = $48/month
- Savings: 47%

3. Quality Difference
Example where wrong model fails:

Flash trying to debug code: generates incorrect fix
Kimi debugging same code: correct fix first try

## Comments


## Links

- None detected yet

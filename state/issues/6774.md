---
number: 6774
title: "supermemory_forget tool returns 404 - doesn't match Supermemory API contract"
author: samdjohnson
created: 2026-02-02T01:46:24Z
updated: 2026-02-02T02:57:08Z
labels: ["bug"]
assignees: []
comments_count: 1
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/6774
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

The `supermemory_forget` tool fails with `404 Document not found` when attempting to delete memories by query, even when `supermemory_search` successfully finds matching memories.

## Steps to Reproduce

1. Store a memory: `supermemory_store` with text "Sam Johnson lives in Denver"
2. Verify it exists: `supermemory_search` query "lives in Denver" → returns matches at 75%+ relevance
3. Try to forget: `supermemory_forget` query "Sam Johnson lives in Denver"
4. Result: `404 {"error":"Document not found"}`

## Root Cause Analysis

The [Supermemory API documentation](https://supermemory.ai/docs/api-reference/memories/forget-a-memory) shows the forget endpoint requires:

```
DELETE /v3/memories/forget
Body:
  - containerTag (REQUIRED) - scopes the operation
  - id (optional) - memory entry ID  
  - content (optional) - EXACT content match
  - reason (optional)
```

**Issues identified:**

1. **Missing containerTag**: The API requires `containerTag` but the tool may not be passing it
2. **Query vs exact match**: The tool accepts a `query` parameter (suggesting semantic search) but the API expects `content` (exact string match)
3. **No memory IDs returned**: `supermemory_search` doesn't return memory IDs, so there's no way to get an ID to pass to forget

## Expected Behavior

Either:
- `supermemory_forget` should do a two-step operation: search → get ID → delete
- `supermemory_search` should return memory IDs that can be passed to forget
- `supermemory_forget` should accept exact content strings and pass them correctly with containerTag

## Environment

- Clawdbot gateway running on macOS
- Supermemory integration enabled
- Tested via Telegram channel

## Impact

Cannot clean up duplicate or outdated memories, leading to profile pollution over time.

## Comments

### @samdjohnson (2026-02-02)

## Additional Root Cause Analysis

After calling the Supermemory API directly, I found a deeper architectural issue:

### How facts are stored

`supermemory_store` appends facts to a **single session document**:

```json
{
  "id": "ur6Ry3FKsURVQXDbUFoFqL",
  "customId": "session_agent_main_main",
  "title": "Clawdbot Interaction Log (Jan 21–Feb 1 2026)...",
  "metadata": {
    "type": "fact",
    "source": "clawdbot_tool"
  }
}
```

All stored facts go into this one document — they're not standalone memory entries.

### Why forget fails

The Supermemory `DELETE /v3/memories/forget` endpoint expects either:
1. A standalone memory document ID
2. An exact content match for a memory

But facts like "Sam Johnson lives in Denver" are:
- Stored as **chunks within a large session document**
- Not queryable as individual deletable units
- The exact stored text may differ from what I'm searching for

### The fix needed

**Option 1:** Store facts as **standalone documents** (one doc per fact) with their own IDs, so forget can delete them individually.

**Option 2:** Implement a "memory entry" layer that tracks individual facts within documents, with their own IDs.

**Option 3:** Use `customId` for each fact (e.g., `fact_sam_lives_denver`) so updates replace rather than append.

The current architecture makes granular memory management impossible — you can only search/retrieve, not delete individual facts.


## Links

- None detected yet

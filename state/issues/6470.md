---
number: 6470
title: "[Bug]: Reasoning/thinking content leaking to Discord regardless of model"
author: DanBennettUK
created: 2026-02-01T17:57:57Z
updated: 2026-02-01T20:58:03Z
labels: ["bug"]
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/6470
duplicate_of: null
related_issues: [1,2]
blocks: []
blocked_by: []
---

## Description

---
name: Bug report
about: Report a problem or unexpected behavior in Clawdbot.
title: "[Bug]: Reasoning/thinking content leaking to Discord"
labels: bug
---

## Summary

Internal reasoning/thinking content from the AI is being transmitted directly to Discord messages, visible to the user. This occurs with both reasoning models (kimi-k2.5:cloud) and non-reasoning models (glm-4.7).

## Steps to reproduce

1. Start any conversation with Clawdbot via Discord
2. Send any message that requires the AI to process
3. Observe the response - internal reasoning/planning is visible before the final output
4. Issue persists across:
   - Model switches (kimi → GLM → kimi)
   - Gateway restarts
   - Session resets (/new, /reset)
   - Context compaction

## Expected behavior

Only the final output (content within final tags) should be sent to Discord. Internal reasoning should be completely filtered and never visible to the user.

## Actual behavior

The AI's internal monologue/reasoning is being broadcast directly to Discord. For example, the user can see messages like:

> "The user is saying... I should... Let me check..."

This appears before or instead of the actual response.

## Environment

- Clawdbot version: 2026.1.30 (76b5208)
- OS: Ubuntu (Linux 6.8.0-90-generic)
- Node: v22.22.0
- Install method: npm
- Primary model: ollama/kimi-k2.5:cloud
- Also affected: zai/glm-4.7 (non-reasoning model)

## Logs or screenshots

### Evidence from OpenClaw logs:

All runs show `thinking=low` parameter, even for non-reasoning models:

```json
{"subsystem":"agent/embedded", "1":"embedded run start: ... model=kimi-k2.5:cloud thinking=low ..."}
{"subsystem":"agent/embedded", "1":"embedded run start: ... model=glm-4.7 thinking=low ..."}
```

### Model configuration:

From `openclaw.json`:
- `kimi-k2.5:cloud`: has `"reasoning": true`
- `glm-4.7`: does NOT have reasoning field (non-reasoning model)

Yet BOTH are being run with `thinking=low`.

### Session memory files:

Multiple session files created documenting this issue:
- `memory/2026-02-01-reasoning-leak.md`
- `memory/2026-02-01-context-overflow.md`

## Additional context

The issue appears to have two components:

1. **BUG #1:** `thinking=low` is being set on ALL model runs, including non-reasoning models like GLM that shouldn't have thinking enabled.

2. **BUG #2:** When models return reasoning content (in the `reasoning` field), OpenClaw is not properly filtering it out before sending to the channel. The reasoning content is being transmitted alongside or instead of the final output.

This is a critical privacy/usability issue as the AI's internal planning is exposed to users, breaking the expected behavior of the system.

## Comments


## Links

- None detected yet

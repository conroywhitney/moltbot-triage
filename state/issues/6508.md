---
number: 6508
title: "Tool calls from active session timeout due to WS self-contention"
author: amco3008
created: 2026-02-01T18:49:42Z
updated: 2026-02-01T21:37:22Z
labels: ["bug"]
assignees: []
comments_count: 2
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/6508
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

When calling tools (e.g. `cron.add`, `cron.list`) from within an active LLM session, the tool call opens a **new WebSocket connection** back to the same gateway that is currently busy processing the session's turn. Since the gateway is single-threaded Node.js, it cannot respond to the second WS request while blocked on the first — resulting in a 10-second timeout.

**The job actually succeeds** (confirmed by checking after timeout), but the tool returns an error to the LLM, which may cause unnecessary retries and duplicate jobs.

## Reproduction

1. Start a Clawdbot session (e.g., via Telegram)
2. From within the session, call `cron add` or `cron list`
3. Observe: WS connects, sends frame (`cron.list`), gateway never responds within 10s
4. Error: `gateway timeout after 10000ms`
5. But: the cron job IS created (check `clawdbot cron list` from CLI — works fine)

## Environment

- Clawdbot 2026.1.24-3
- Node 22.22.0
- Gateway bind: `tailnet` (single Tailscale IP)
- Linux (Docker, WSL2)
- Two instances running (separate containers, separate gateways)

## Root Cause

The embedded tool runner opens a **second WS connection** to the gateway to execute `cron.*` operations. The gateway's event loop is busy processing the current LLM turn (waiting for API response + tool execution). The second WS request sits in the queue, never gets processed within the timeout window.

Key evidence from logs:
```
→ close code=1005 reason= durationMs=10009 handshake=connected lastFrameType=req lastFrameMethod=cron.list
```
The WS connected, sent the frame, but the gateway never responded.

## Workaround

Use `exec` tool to call CLI instead of native tool:
```bash
clawdbot cron list
clawdbot cron add --name my-job --schedule '0 */6 * * *' ...
```
CLI runs as a separate process with its own WS connection and no active session blocking the event loop.

## Proposed Fix

**Option A (preferred):** Route embedded tool calls through the existing session WS channel instead of opening a new connection. The session already has an active WS — `cron.*` requests could be multiplexed on it.

**Option B (simpler):** Use in-process function calls for tools that are part of the gateway itself (cron, gateway config, etc.) instead of going through WS at all.

**Option C (band-aid):** Increase default timeout for embedded tool WS calls, or make it configurable per-tool.

## Impact

- Affects any tool that routes through gateway WS from within a session
- Confirmed on `cron.add`, `cron.list`
- May affect `gateway` tool calls under heavy load
- Risk of duplicate cron jobs if LLM retries on false timeout error

## Comments

### @amco3008 (2026-02-01)

## Additional Diagnostic Data (from Vroth-Markets instance)

I investigated this from the second Clawdbot instance (separate container, same Tailscale mesh). Here are findings that support and extend the root cause analysis:

### Key Evidence

**1. Internal tool vs WS tool divergence:**
- `cron` tool called from within an active session: **works instantly** (14 jobs returned, no delay). This uses the in-process IPC path (`server-bridge-methods-*.js`), NOT WebSocket.
- Custom WS client connecting to gateway: connects in **16ms**, responds in **17ms** — when there is no active session blocking the loop.
- The timeout only occurs when the *same* gateway is already processing an LLM turn.

**2. Auth handshake sequencing:**
The gateway WS protocol requires a `connect.challenge` handshake (nonce exchange) before accepting any command frames. If a new WS connection sends `cron.list` without completing the challenge, the gateway silently drops it — no error, no response. This looks identical to a timeout from the client perspective but the root cause is different from event loop blocking.

From the logs: `close code=1005 reason= durationMs=10009 handshake=connected lastFrameType=req lastFrameMethod=cron.list` — the `handshake=connected` confirms the challenge WAS completed, so in this case it IS the event loop blocking (Option A/B territory, not auth).

**3. Gateway resource state during timeouts:**
- 486MB RAM, 7.3% CPU, load avg 0.58
- No memory pressure, no GC pauses
- Binding: Tailscale IP only (100.95.164.59:18789), internal ports 18791/18792 are browser control
- This rules out resource exhaustion — it is purely the single-threaded event loop being occupied.

### Fix Preference

Strongly support **Option B** (in-process function calls for gateway-native tools). Evidence:
- The internal `cron` tool already uses IPC and works perfectly from active sessions
- The WS path is only needed for *external* clients
- Routing embedded tool calls through IPC instead of WS would be zero-overhead and immune to event loop contention
- This is exactly how tools like `gateway.config.get` already work internally

**Option A** (multiplexing on existing session WS) would also work but adds protocol complexity. Option B is simpler and more robust.

### CLI Workaround Validated

Confirmed: `clawdbot cron list` from `exec` tool works reliably because it spawns a separate process with its own event loop. We use `timeoutMs: 60000` as a belt-and-suspenders measure, but the exec approach is the real fix for now.

---
*Diagnostic data from Vroth-Markets (agent-mobile-1, Clawdbot 2026.1.24-3, same environment as OP)*

### @lofimichael (2026-02-01)

Getting this issue too; gateway is hanging, got dozens of zombie jobs. As a workaround to avoid this issue, I'm installing sensors/dispatches using system cron bash scripts manually.

<img width="987" height="474" alt="Image" src="https://github.com/user-attachments/assets/2c814a93-abd6-4d1d-837e-3ec06e1acbbf" />


## Links

- None detected yet

---
number: 3209
title: "[Feature]: Add CometAPI as an Model provider"
author: tensornull
created: 2026-01-28T07:50:46Z
updated: 2026-01-28T10:25:21Z
labels: ["enhancement"]
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/3209
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

We are the official **CometAPI** team. Every day, we receive numerous requests from users seeking help to configure CometAPI in moltbot. 

While CometAPI is fully OpenAI-compatible and can technically work via the "OpenAI Compatible" provider option, we've found that the model configuration process is cumbersome and error-prone for end users. They need to manually input model names, manage base URLs, and lack model discoverability—leading to a suboptimal experience.

The native integration of CometAPI will enable our users to seamlessly access over 500 models (including state-of-the-art models from OpenAI, Anthropic, Google, Grok, DeepSeek, Qwen, and more) with minimal configuration. More importantly, CometAPI offers competitive price discounts—especially in scenarios like Agents that consume a large number of tokens—allowing users to save substantial costs.

## Proposed solution

Add **CometAPI** as a first-class model provider in moltbot with:

- **Pre-configured model list**: Built-in access to all available models with automatic updates
- **Simple setup**: Users only need to enter their CometAPI API key
- **Full streaming support**: Compatible with chat completions streaming
- **Model discovery**: Dynamic model listing via API endpoint

### CometAPI Resources

| Resource | Link |
|----------|------|
| Website | https://www.cometapi.com/ |
| API Documentation | https://apidoc.cometapi.com/ |
| API Key Console | https://api.cometapi.com/console/token |
| Base URL | `https://api.cometapi.com/v1` |

### Technical Details

CometAPI is fully compatible with the OpenAI SDK format:

```python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.cometapi.com/v1",
    api_key="<YOUR_COMETAPI_KEY>"
)

response = client.chat.completions.create(
    model="gpt-5.2-chat-latest",
    messages=[{"role": "user", "content": "Hello moltbot"}]
)
```

## Alternatives considered

- **Current workaround**: Configure CometAPI as a custom OpenAI-compatible provider. This works but requires manual model configuration for each model and lacks discoverability.
- **Documentation approach**: Provide detailed setup guides for users—but this still places significant burden on users and doesn't solve the UX issues.

## Additional context

### Our Commitment

- ✅ We are willing to follow community guidelines and **submit a PR** for this integration
- ✅ We will provide **test API keys** for CI/testing purposes
- ✅ We commit to **ongoing maintenance** for any CometAPI-related issues in the future

## Comments


## Links

- None detected yet

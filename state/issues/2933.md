---
number: 2933
title: "[Feature]: Integrations with Private Inference methods"
author: Murad-Awad
created: 2026-01-27T19:50:55Z
updated: 2026-01-29T18:37:29Z
labels: ["enhancement"]
assignees: []
comments_count: 1
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/2933
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary
Clawdbot is super useful but has access to a ton of personal data; this data will leak to the model providers currently being used. I would appreciate integration with cloud hosted privacy centric LLM inference offerings. I am currently working on one that would require webauthn keys stored on device + encryption keys for each message stored on device. It also uses a double ratcheted noise pipe protocol directly to a TEE hosting an LLM to ensure that unencrypted data is seen for as little time as possible, is zeroed out, and basically ensures that personal information cannot be seen by even the OS running the LLM. There are other offerings out there like https://confer.to/ that I think the community could benefit from in the meantime.

## Comments

### @Bai-shisheng (2026-01-29)

Locally, information such as privacy and passwords should be encrypted and decrypted automatically by calling a password authenticator, rather than being transmitted to the cloud model.


## Links

- None detected yet

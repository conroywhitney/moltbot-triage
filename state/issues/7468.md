---
number: 7468
title: "[Feature]: Dynamic Model Selection Based on Context Size"
author: steromano87
created: 2026-02-02T21:24:04Z
updated: 2026-02-02T21:36:03Z
labels: []
assignees: []
comments_count: 1
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/7468
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

Currently, OpenClaw uses a fixed model selection strategy (primary + fallback chain) regardless of the input prompt size. This means that small queries use the same expensive/powerful model as large, complex ones, leading to:
- **Unnecessary costs** for simple tasks
- **Suboptimal performance** when a lighter model would suffice
- **Missed opportunities** to use specialized models based on workload

## Proposed solution

Add **automatic model routing** based on **configurable context size thresholds**. 

Example configuration:

```json5
{
  "agents": {
    "defaults": {
      "modelRouting": {
        "enabled": true,
        "strategy": "context-size",
        "thresholds": [
          {
            "maxTokens": 4000,
            "model": "anthropic/claude-haiku-4-5",
            "description": "Lightweight tasks"
          },
          {
            "maxTokens": 100000,
            "model": "anthropic/claude-sonnet-4-5",
            "description": "Medium complexity"
          },
          {
            "maxTokens": null,
            "model": "anthropic/claude-opus-4-5",
            "description": "Complex/large context"
          }
        ],
        "fallbackOnOverflow": true
      }
    }
  }
}
```

**How it would work:**
1. Before sending a request, OpenClaw estimates the **total context size** (system prompt + history + user message + tool outputs)
2. Select the **first model** in the threshold chain where `contextTokens <= maxTokens`
3. If all thresholds are exceeded, use the last model or fall back to configured fallbacks
4. Optionally log routing decisions for debugging (`--verbose` or diagnostics)

## Alternatives considered

1. **Manual model switching via `/model`**  
   ✅ Already available  
   ❌ Requires manual intervention every session

2. **Multi-agent routing with bindings**  
   ✅ Works for channel/user-based routing  
   ❌ Not dynamic per-message; requires predefined agent configs

3. **Custom hooks**  
   ✅ Technically possible  
   ❌ Complex, undocumented, requires TypeScript knowledge

4. **External proxy/middleware**  
   ✅ Could work with custom provider config  
   ❌ Adds complexity, defeats integrated OpenClaw experience

## Additional context

**Use cases:**
- **Cost optimization**: Route small queries to Haiku, complex ones to Opus
- **Latency optimization**: Use faster models for simple tasks
- **Specialized routing**: Use reasoning models (o1/o3) only for complex problems
- **Token window management**: Automatically switch to larger-context models when needed

**Related tooling:**
- Similar to how IntelliJ IDEA and other tools support **dynamic Copilot routing** for Enterprise setups
- OpenRouter already supports model routing based on provider availability

**Compatibility:**
- Should work alongside existing `model.primary` + `model.fallbacks` (routing happens *before* fallback chain)
- Could be opt-in via `modelRouting.enabled: false` (default)

## Comments

### @kshitijgetsac (2026-02-02)

based on your suggestion I don't think context size is the right criteria to decide what model should be used, rather there can be a smaller model sitting on top of your queries that probably can decide which model to route the request to since if I want to solve a complex math problem the question can fit into say 2-3 lines but the model choice needs to be accurate in this case since a smaller model wouldn't be able to suffice in this case 


## Links

- None detected yet

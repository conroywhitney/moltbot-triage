---
number: 6413
title: "CRITICAL: Gateway process massive virtual memory leak (22GB+) - regenerates immediately after restart"
author: unchainedio
created: 2026-02-01T16:52:20Z
updated: 2026-02-01T21:03:58Z
labels: ["bug"]
assignees: []
comments_count: 3
reactions_total: 1
url: https://github.com/openclaw/openclaw/issues/6413
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## ðŸ› Bug Description

The `openclaw-gateway` process has a **severe virtual memory leak** causing VSZ to balloon to **22+ GB** within minutes of starting. This happens **immediately and consistently** on every restart, even with minimal activity.

## ðŸ“Š Environment

| Component | Version/Details |
|-----------|----------------|
| **OpenClaw** | 2026.1.30 |
| **OS** | Ubuntu 24.04 LTS |
| **Kernel** | Linux 6.8.0-90-generic x64 |
| **Node.js** | v22.22.0 |
| **Installation** | npm global (pnpm) |
| **RAM** | 3.7 GB |
| **Swap** | 4 GB (added as mitigation) |

## ðŸ”´ Critical Symptoms

### Memory Usage Pattern
```
PID       %MEM    VSZ        RSS    COMMAND
648981    10.7%   22734080   418688 openclaw-gateway
```

- **VSZ (Virtual Memory):** 22.7 GB and growing
- **RSS (Physical Memory):** ~400-500 MB (normal)
- **Growth Rate:** Reaches 22GB within 1-2 minutes of restart
- **Persistence:** Returns immediately after every restart

### Memory Mapping Analysis
- Two **8 GB anonymous mappings**
- Multiple **2 GB anonymous mappings**
- Numerous **64 MB mappings**
- Pattern suggests mmap() overcommit or heap fragmentation

## ðŸ”„ Reproduction Steps

1. **Start OpenClaw:** `openclaw gateway start`
2. **Monitor:** `watch -n 5 'ps aux | grep openclaw-gateway'`
3. **Observe:** VSZ grows to 22GB within 60-120 seconds
4. **Restart:** `openclaw gateway restart`
5. **Result:** Memory returns to 22GB immediately

## âœ… Tested Mitigations (Failed)

| Attempt | Result |
|---------|--------|
| Restart gateway | âŒ Leak returns immediately |
| Clear sub-agents | âŒ Not related to sub-agents |
| Update to latest (2026.1.30) | âŒ Already on latest, no fix |
| Check session files | âŒ Session files only ~2MB |
| Check for zombie processes | âŒ None found |
| 4GB swap added | âœ… Prevents OOM crashes only |

## ðŸ›¡ï¸ Current Workaround

**Auto-heal system implemented:**
- Monitors gateway VSZ every 5 minutes
- Triggers restart at 15GB threshold
- Saves conversation context before restart
- Commits config changes to git
- System stable but restart-heavy (~every 10-15 min)

## ðŸ“ˆ Impact Assessment

- **Severity:** ðŸ”´ CRITICAL
- **System Stability:** At risk without swap
- **User Experience:** Disrupted by frequent restarts
- **Data Integrity:** No data loss (context preserved)
- **Workaround Effectiveness:** 70% (stable but noisy)

## ðŸ” Root Cause Hypothesis

1. **Memory-mapped file leak** â€” mmap() regions not being released
2. **Node.js heap fragmentation** â€” V8 heap growing unbounded
3. **WebSocket connection leak** â€” Connection objects accumulating
4. **Event loop accumulation** â€” Callbacks/events not being cleaned up

## ðŸ“Ž Additional Context

- **Issue started:** ~2026-02-01 14:00 UTC
- **First noticed:** During dashboard/Tailscale configuration
- **Not related to:** Session file bloat, sub-agents, cron jobs
- **Process count:** Normal (~143 total system processes)
- **No orphaned Node.js processes detected**

## ðŸ™‹ Request

**URGENT:** Please investigate and release a patch. Happy to provide:
- Heap dumps
- strace logs
- Additional diagnostics
- Testing of fixes

---
*Reported by: @unchainedio*
*Affected system: Production deployment*

## Comments

### @unchainedio (2026-02-01)

## System Information
Date: Sun Feb  1 04:54:30 PM UTC 2026
Uptime:  16:54:30 up 3 days,  8:54,  2 users,  load average: 0.83, 0.80, 0.73

## Kernel
Linux moltbot 6.8.0-90-generic #91-Ubuntu SMP PREEMPT_DYNAMIC Tue Nov 18 14:14:30 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux

## Memory
               total        used        free      shared  buff/cache   available
Mem:           3.7Gi       1.3Gi       1.3Gi       4.2Mi       1.4Gi       2.4Gi
Swap:          4.0Gi        34Mi       4.0Gi

## Disk
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1        38G   28G  8.5G  77% /

## Node.js Version
v22.22.0

## NPM Version
10.9.4

## OpenClaw Version
2026.1.30

## Gateway Process Details
moltbot   648981  1.9 11.8 22772192 464944 ?     Sl   16:05   0:58 openclaw-gateway

## Memory Maps (anonymous only)

## Open File Descriptors (count)
42

## Process Limits
Max data size             unlimited            unlimited            bytes     
Max resident set          unlimited            unlimited            bytes     
Max open files            524288               524288               files     

## Network Connections (count)
231

## System Limits
real-time non-blocking time  (microseconds, -R) unlimited
core file size              (blocks, -c) 0
data seg size               (kbytes, -d) unlimited
scheduling priority                 (-e) 0
file size                   (blocks, -f) unlimited
pending signals                     (-i) 15127
max locked memory           (kbytes, -l) 8192
max memory size             (kbytes, -m) unlimited
open files                          (-n) 524288
pipe size                (512 bytes, -p) 8


### @unchainedio (2026-02-01)

## Update: Root Cause Analysis

After further investigation, I've **disabled** both suspected features and the memory leak **still persists**:

### Features Disabled:
- .compaction.memoryFlush.enabled: false

### @unchainedio (2026-02-01)

## Update: Root Cause Analysis

After further investigation, I have DISABLED both suspected features and the memory leak STILL PERSISTS:

### Features Disabled:
- compaction.memoryFlush.enabled: false
- memorySearch.experimental.sessionMemory: false

### Result After Restart:
- VSZ: Still 22GB+ immediately after gateway restart
- RSS: ~430MB (normal)

### Conclusion:
The memory leak is NOT caused by memoryFlush or sessionMemory features. The issue is deeper in the openclaw-gateway Node.js process itself.

### Additional Context:
The leak appears immediately on process startup - suggesting it may be related to:
1. Native module loading
2. Initial memory allocation patterns
3. Something in the gateway bootstrap process
4. Possibly related to session storage or compaction logic

The auto-heal system is managing this by restarting the gateway when VSZ > 15GB, but this is a workaround, not a fix.

---
Testing environment: OpenClaw 2026.1.30, Node v22.22.0, Ubuntu 22.04


## Links

- None detected yet

---
number: 5771
title: "[Bug]: Context overflow error"
author: realQhimself
created: 2026-01-31T23:32:55Z
updated: 2026-02-02T18:55:40Z
labels: ["bug"]
assignees: []
comments_count: 4
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/5771
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

Context overflow error occurs on fresh sessions with minimal workspace, even after deleting all memory databases and simplifying configuration files. The agent becomes unusable after 2-3 messages.

## Steps to reproduce

1. Delete all memory: `rm -rf ~/.openclaw/memory/*`
2. Delete workspace memory files: `rm -rf ~/.openclaw/workspace/memory/*`
3. Simplify `AGENTS.md` to ~30 lines, delete `MEMORY.md`, `SOUL.md`, `USER.md`, etc.
4. Delete any `node_modules` folders in workspace projects
5. Restart gateway: `pkill -9 -f openclaw && nohup openclaw gateway run --bind loopback --port 18789 &`
6. Send `/new` in Telegram to start fresh session
7. Send 2-3 short messages like "Hello" and "How are you?"

## Expected behavior

A new session with minimal workspace should handle simple messages without overflow.

## Actual behavior

After 2-3 messages, any subsequent message triggers:
```
Context overflow: prompt too large for the model. Try again with less input or a larger-context model.
```

The issue persists despite:
- Deleting 12MB `main.sqlite` memory database
- Removing all `node_modules` directories
- Simplifying `AGENTS.md` to minimal content
- Starting fresh sessions with `/new`

## Environment

- Clawdbot version: 2026.1.29 (a5b4d22)
- OS: Linux (Ubuntu on GCP VM)
- Install method: direct install
- Model: google/gemini-2.0-flash
- Interface: Telegram bot

## Logs or screenshots

Gateway starts successfully with no errors:
```
[gateway] agent model: google/gemini-2.0-flash
[gateway] listening on ws://127.0.0.1:18789
[telegram] [default] starting provider (@YourBotName)
```

No errors appear in `/tmp/openclaw.log` before the overflow occurs.

---

### Additional Notes

**Workaround attempts that failed:**
- `agents.defaults.autoCompact: true` → "Unrecognized key: autoCompact"
- `agent.autoCompact: true` → "agent.* was moved" validation error (causes startup crash loop)

**Feature requests:**
1. Add option to completely disable memory/RAG
2. Add context size limit configuration
3. Provide token count visibility for debugging
4. Fix/document the correct `autoCompact` configuration path

## Comments

### @chazbotsandbox-ops (2026-02-01)

## Workaround

The root cause is that Flash models have smaller context windows, and clawdbot injects boot files + memory search results + conversation history, which can quickly overflow.

### Solution: Disable memory search for Flash-based agents

In your `clawdbot.json`, add `memorySearch.enabled: false` to agents using Flash models:

```json
{
  "id": "your-agent",
  "model": {
    "primary": "google/gemini-2.0-flash"
  },
  "memorySearch": {
    "enabled": false
  }
}
```

### Notes on config paths

- **`compaction`** - Only valid at `agents.defaults` level, NOT per-agent (this is why you got "Unrecognized key" errors)
- **`memorySearch.enabled`** - Valid per-agent, this is what you want to disable

### Example defaults-level compaction:

```json
"agents": {
  "defaults": {
    "compaction": {
      "mode": "safeguard"
    }
  }
}
```

### Additional recommendations for Flash models:

1. Trim boot files - keep `AGENTS.md` minimal (under 50 lines)
2. Remove unnecessary `.md` files from workspace root
3. Use `/new` frequently to start fresh sessions
4. Avoid memory-heavy features like `sessionMemory: true`

This worked for me with `google/gemini-3-flash` agents that were previously overflowing.

### @osmanates (2026-02-01)

In my case, i have the same error daily basis. I first thought that gemini flash preview model hit context limit but then i enabled logging in ai studio. After that when open claw says context overflow, i can see the last response in ai studio for my last exchange. This must be something else. Even if i try with a new session, this might happen. Context and tokens isn't even close to 100k. So, limit exceed doesn't make sense for me. And from what i understand flash model also has 1M token just like pro model.

### @HalbardHobby (2026-02-02)

I have the same issue, Not even 20k tokens in, and the bot becomes unusable. Also tried a new session, and got the same error

### @osmanates (2026-02-02)

I actually found the issue. The issue is with context/token checks. Openclaw thinks the model hit the limit if the response of gemini has context overflow text in it.  If you directly type context overflow e.g. in telegram you will instantly get the same error. Plus a few more texts that cause similar issues. In reality in this case you didn't hit the limit. It just Openclaw thinks you did since the gemini response has text in it.

In my case i actually hit the 1m token limit once then start a new session but somehow openclaw still has the error text that causes gemini to reply with it so issue happens again. You can instruct openclaw to not include that text in any prompt to gemini that should hopefully fix issue in that session assuming you didn't hit limit. I have a fork of openclaw that you can try build and run for a more permanent fix. I also have a improved one that is on my computer. If i have time, i can do a pull request. If you enable logging in ai studio if you use gemini api key, you will see gemini actually responds.


## Links

- None detected yet

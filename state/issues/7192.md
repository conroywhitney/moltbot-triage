---
number: 7192
title: "Feature Request: Typing/Thinking Indicator Support"
author: tracky2009
created: 2026-02-02T14:46:03Z
updated: 2026-02-03T01:07:45Z
labels: []
assignees: []
comments_count: 1
reactions_total: 2
url: https://github.com/openclaw/openclaw/issues/7192
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Feature Request: Typing/Thinking Indicator Support

### Problem
When using slower models (e.g., Kimi K2.5) or complex reasoning tasks, users don't know if the agent is processing or stuck. This creates a poor UX.

### Proposed Solution
Add support for sending intermediate "thinking/processing" indicators:

1. **iMessage**: Use typing indicator (if protocol supports)
2. **Feishu/Lark**: Support `typing` message type or emoji reactions
3. **Other channels**: Send intermediate "Processing..." message before final response

### Use Cases
- Long-running reasoning tasks
- Multi-step tool executions
- Slow model inference (Kimi, GPT-4, etc.)

### Technical Approach Options
Option A (Safe): Send "Processing..." text message immediately, then edit/update with final response
Option B (Native): Use platform-specific typing indicators where available

### Priority
Medium - Nice to have for better UX, but not blocking

/cc @maintainers

## Comments

### @rahultappetla (2026-02-03)

I've opened a PR that addresses this: #6778                                                                                                                                                                                      
                                                                                                                                                                                                                                   
  It adds a configurable `typingTtlSeconds` option (default: 120s) that lets users extend how long the typing indicator stays active. For slow models like Kimi K2.5 or complex reasoning tasks, you can now set:                  
                                                                                                                                                                                                                                   
  ```json5                                                                                                                                                                                                                         
  {                                                                                                                                                                                                                                
    agents: {                                                                                                                                                                                                                      
      defaults: {                                                                                                                                                                                                                  
        typingTtlSeconds: 300,  // 5 minutes                                                                                                                                                                                       
      },                                                                                                                                                                                                                           
    },                                                                                                                                                                                                                             
  }                                                                                                                                                                                                                                
                                                                                                                                                                                                                                   
  This keeps the indicator running during long inference, so users know the agent is still processing.                                                                                                                             
          


## Links

- None detected yet

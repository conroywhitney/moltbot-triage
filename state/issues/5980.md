---
number: 5980
title: "[Bug]: NVIDIA NIM provider causes gateway to hang/freeze during requests"
author: dragontpe
created: 2026-02-01T05:08:40Z
updated: 2026-02-02T00:17:03Z
labels: ["bug"]
assignees: []
comments_count: 3
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/5980
duplicate_of: null
related_issues: [4857]
blocks: []
blocked_by: []
---

## Description

## Description                                                                                         
                                                                                                         
  When configuring NVIDIA NIM (moonshotai/kimi-k2.5) as a custom OpenAI-compatible provider, the gateway 
  accepts the configuration but hangs indefinitely when processing requests. The agent gets stuck in the 
  compaction phase and never responds to user messages.                                                  
                                                                                                         
  ## Environment                                                                                         
                                                                                                         
  - **OpenClaw Version**: 2026.1.30 (76b5208)                                                            
  - **OS**: macOS (Darwin 25.2.0)                                                                        
  - **Node Version**: v22.18.0                                                                           
  - **Installation Method**: npm global                                                                  
                                                                                                         
  ## Configuration                                                                                       
                                                                                                         
  ### openclaw.json                                                                                      
  ```json                                                                                                
  {                                                                                                      
    "models": {                                                                                          
      "mode": "merge",                                                                                   
      "providers": {                                                                                     
        "nvidia": {                                                                                      
          "baseUrl": "https://integrate.api.nvidia.com/v1",                                              
          "apiKey": "${NVIDIA_API_KEY}",                                                                 
          "api": "openai-completions",                                                                   
          "models": [{                                                                                   
            "id": "moonshotai/kimi-k2.5",                                                                
            "name": "Kimi K2.5 (NVIDIA Free)",                                                           
            "contextWindow": 128000,                                                                     
            "maxTokens": 4096,                                                                           
            "reasoning": false                                                                           
          }]                                                                                             
        }                                                                                                
      }                                                                                                  
    },                                                                                                   
    "agents": {                                                                                          
      "defaults": {                                                                                      
        "model": {                                                                                       
          "primary": "nvidia/moonshotai/kimi-k2.5",                                                      
          "fallbacks": [                                                                                 
            "openrouter/google/gemini-2.5-flash"                                                         
          ]                                                                                              
        }                                                                                                
      }                                                                                                  
    }                                                                                                    
  }                                                                                                      
                                                                                                         
  auth-profiles.json                                                                                     
                                                                                                         
  {                                                                                                      
    "profiles": {                                                                                        
      "nvidia:default": {                                                                                
        "type": "api_key",                                                                               
        "provider": "nvidia",                                                                            
        "key": "nvapi-..."                                                                               
      }                                                                                                  
    }                                                                                                    
  }                                                                                                      
                                                                                                         
  Steps to Reproduce                                                                                     
                                                                                                         
  1. Configure NVIDIA NIM provider as shown above                                                        
  2. Start gateway: openclaw gateway                                                                     
  3. Gateway starts successfully and shows: agent model: nvidia/moonshotai/kimi-k2.5                     
  4. Open Web UI and send any message                                                                    
  5. Request hangs indefinitely - no response, no error                                                  
                                                                                                         
  Expected Behavior                                                                                      
                                                                                                         
  The model should respond to user messages, similar to how OpenRouter or Anthropic providers work.      
                                                                                                         
  Actual Behavior                                                                                        
                                                                                                         
  - Gateway logs show request starts: embedded run start: provider=nvidia model=moonshotai/kimi-k2.5     
  - Request proceeds to embedded run agent end after ~60 seconds                                         
  - Then enters embedded run compaction start phase                                                      
  - Stays stuck in this phase indefinitely (3+ minutes observed)                                         
  - No error messages, just keeps showing run active check: active=true                                  
  - Web UI shows loading spinner forever                                                                 
                                                                                                         
  Verification                                                                                           
                                                                                                         
  NVIDIA API works perfectly when tested directly:                                                       
  curl -X POST "https://integrate.api.nvidia.com/v1/chat/completions" \                                  
    -H "Authorization: Bearer nvapi-..." \                                                               
    -H "Content-Type: application/json" \                                                                
    -d '{                                                                                                
      "model": "moonshotai/kimi-k2.5",                                                                   
      "messages": [{"role": "user", "content": "Hello"}],                                                
      "max_tokens": 10                                                                                   
    }'                                                                                                   
  # Returns response in ~1 second                                                                        
                                                                                                         
  Logs                                                                                                   
                                                                                                         
  {"subsystem":"agent/embedded","message":"embedded run start: provider=nvidia model=moonshotai/kimi-k2.5
   thinking=off"}                                                                                        
  {"subsystem":"agent/embedded","message":"embedded run agent end"}                                      
  {"subsystem":"agent/embedded","message":"embedded run compaction start"}                               
  {"subsystem":"diagnostic","message":"run active check: sessionId=... active=true"}                     
  [repeated indefinitely]                                                                                
                                                                                                         
  Workaround                                                                                             
                                                                                                         
  Switching to openrouter/google/gemini-2.5-flash works immediately without issues.                      
                                                                                                         
  Possible Related Issue                                                                                 
                                                                                                         
  This might be related to #4857 (custom openai providers crash with "Unhandled API" error), as NVIDIA   
  NIM uses an OpenAI-compatible API.                                                                     
                                                                                                         
  Additional Context                                                                                     
                                                                                                         
  - openclaw models list correctly shows the model as configured with auth                               
  - No authentication errors in logs                                                                     
  - Same issue occurs even with reasoning: false explicitly set                                          
  - Gateway startup shows no errors about the provider configuration                                     
                                                                          

## Comments

### @snowf14k3 (2026-02-01)

use this config,try replace minimaxai/minimax-m2 to moonshotai/kimi-k2.5

```json
{
  "agents": {
    "defaults": {
      "model": {
        "primary": "nvidia_free/minimaxai/minimax-m2"
      },
      "models": {
        "nvidia_free/minimaxai/minimax-m2": {
          "alias": "minimax-m2"
        }
      }
    }
  },
  "models": {
    "mode": "merge",
    "providers": {
      "nvidia_free": {
        "baseUrl": "https://integrate.api.nvidia.com/v1",
        "apiKey": "nvapi-xxxxxx",
        "api": "openai-completions",
        "models": [
          {
            "id": "minimaxai/minimax-m2",
            "name": "minimaxai/minimax-m2",
            "reasoning": false,
            "input": [
              "text"
            ],
            "cost": {
              "input": 0,
              "output": 0,
              "cacheRead": 0,
              "cacheWrite": 0
            },
            "contextWindow": 128000,
            "maxTokens": 32000
          }
        ]
      }
    }
  }
}
```

### @dragontpe (2026-02-01)

Tried the suggested config with `minimaxai/minimax-m2` but experiencing the same issue.

**What happens:**
- Message sent in Web UI doesn't appear
- No response received
- Gateway hangs during compaction phase

**Logs:**
```
09:09:31 - embedded run start: provider=nvidia model=minimaxai/minimax-m2
09:09:31 - embedded run compaction start
[HANGS HERE - never completes]
09:10:11 - run active check: active=true (still stuck)
09:10:16 - run active check: active=true (still stuck)
```

The session gets stuck in compaction and never returns a response. Have to kill the gateway process to recover.

Switched back to Gemini as primary model for now. Let me know if you need full logs or additional debugging info.

### @wesele (2026-02-01)

I experienced the same issue, send 2nd message can get response from 1st messsage.


## Links

- None detected yet

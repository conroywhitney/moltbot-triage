---
number: 6830
title: "Runtime model in system prompt doesn't update on mid-session model switch"
author: BarbaricBrush
created: 2026-02-02T03:15:19Z
updated: 2026-02-02T07:15:25Z
labels: []
assignees: []
comments_count: 1
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/6830
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Description

When a model is switched mid-conversation (e.g., from `opencode/claude-opus-4-5` to `openai/gpt-5.1-codex-mini`), the `model=` value in the runtime line injected into the system prompt remains stale.

## Current Behavior

- Runtime line shows: `model=opencode/claude-opus-4-5`
- Actual model (per `session_status`): `openai/gpt-5.1-codex-mini`

This causes confusion when the agent checks what model it's running â€” the system prompt says one thing, the live status says another.

## Expected Behavior

Either:
1. The runtime line should update when the model changes mid-session, or
2. The agent should be instructed to always trust `session_status` over the runtime line (document the quirk)

## Impact

Low â€” cosmetic/UX confusion, not functional. But can mislead the agent into thinking it's on a different model than it actually is.

## Environment

- OpenClaw 2026.1.30 (76b5208)
- Channel: webchat

## Comments

### @guiambros (2026-02-02)

I'm experiencing something similar. If I change the default model mid-conversation, whenever I restart the session the agent still thinks it's using a different model. But status and logs indicate it is still using the default model, despite what it says in the intro.

**/new**

> Ahoy! Agent X here, ready for a fresh start running on Gemini 3 Pro (default is Kimi K2.5). What's on the horizon for us today?

**/status**

ğŸ¦ OpenClaw 2026.1.30 (76b5208)
ğŸ§  Model: kimi-coding/k2p5 Â· ğŸ”‘ api-key sk-xxxâ€¦xxxxxx (kimi-coding:default)
ğŸ§® Tokens: 13k in / 165 out
ğŸ“š Context: 26k/1.0m (3%) Â· ğŸ§¹ Compactions: 0
ğŸ§µ Session: agent:main:main â€¢ updated just now
âš™ï¸ Runtime: direct Â· Think: low
ğŸ”Š Voice: always Â· provider=edge Â· limit=1500 Â· summary=on
ğŸª¢ Queue: collect (depth 0)




## Links

- None detected yet

---
number: 6054
title: "Custom LLM provider config missing 'api' field causes 'No API provider registered' error with unhelpful message"
author: thegdsks
created: 2026-02-01T07:09:42Z
updated: 2026-02-01T21:04:42Z
labels: ["bug"]
assignees: []
comments_count: 0
reactions_total: 2
url: https://github.com/openclaw/openclaw/issues/6054
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Description

When configuring a custom LLM provider (e.g., LiteLLM proxy to Azure OpenAI), the configuration fails silently or with an unhelpful error message:

```
No API provider registered for api: undefined
```

## Problem

The required fields for custom provider configuration are not clearly documented, and the error messages provide no guidance on what's missing. Specifically:

1. The `"api": "openai-completions"` field is required but not mentioned in error messages when missing
2. The `"mode": "merge"` field is also required for the config to work properly
3. Environment variables like `OPENAI_BASE_URL` are ignored by the embedded agent, which is unexpected behavior
4. It took significant debugging and digging through documentation to discover the correct config structure

## Working Configuration

After extensive debugging, this configuration structure works:

```json
{
  "models": {
    "mode": "merge",
    "providers": {
      "litellm": {
        "baseUrl": "http://localhost:4000/v1",
        "apiKey": "your-key",
        "api": "openai-completions",
        "models": [...]
      }
    }
  }
}
```

## Suggestions

1. **Better error messages**: When the `api` field is missing from a provider configuration, the error message should explicitly state: "Missing required field 'api' in provider configuration. Expected values: 'openai-completions', 'anthropic', etc."

2. **Improved documentation visibility**: The required fields (`api`, `mode`) should be prominently documented in:
   - The configuration error output
   - The README or main documentation
   - Any config schema/validation output

3. **Config validation**: Add upfront validation that checks for required fields before attempting to use the provider, with clear messages about what's missing.

## Environment

- Custom LLM provider: LiteLLM proxy to Azure OpenAI
- Configuration method: JSON config file

## Comments


## Links

- None detected yet

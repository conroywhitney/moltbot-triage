---
number: 2397
title: "Memory flush uses stale token count, fires after compaction instead of before"
author: marcmeezy
created: 2026-01-26T21:26:19Z
updated: 2026-01-28T06:02:03Z
labels: ["bug"]
assignees: []
comments_count: 2
reactions_total: 3
url: https://github.com/openclaw/openclaw/issues/2397
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Bug Description

The pre-compaction memory flush fires **after** compaction occurs instead of before, resulting in lost context.

## Root Cause

In `memory-flush.js`, `shouldRunMemoryFlush()` checks `params.entry?.totalTokens` which only reflects **input tokens from the previous API call**, not the actual current context size.

The issue is that `totalTokens` doesn't account for:
1. The **output tokens** from the last response
2. The new user message

### Example Timeline

```
Run N ends:
  - API reports promptTokens = 170k (input to that run)
  - totalTokens = 170k (stored in session)

User sends new message:
  - shouldRunMemoryFlush checks: 170k < 176k threshold? YES → no flush
  - Main run proceeds
  - Actual context is now: 170k + output (~10k) + new msg (~2k) = 182k
  - 182k > 180k compaction threshold → COMPACTION FIRES
  - Flush prompt arrives 30 sec later to already-compacted session
```

## Evidence

From session transcript:
```
20:47:18 — COMPACTION happened (tokensBefore: 186006)
20:47:48 — Memory flush prompt sent (30 seconds AFTER compaction)
```

## Proposed Fix

In `memory-flush.js`, change:

```js
const totalTokens = params.entry?.totalTokens;
```

to:

```js
const totalTokens = (params.entry?.totalTokens ?? 0) + (params.entry?.outputTokens ?? 0);
```

This accounts for the output tokens, making the estimate much closer to actual context size. The only unknown becomes the new user message (~2k tokens), so the default 4000 token threshold would actually work correctly.

## Session Store Already Tracks Output

`session-usage.js` already stores `outputTokens` separately:
```js
outputTokens: output,
totalTokens: promptTokens > 0 ? promptTokens : (params.usage?.total ?? input),
```

So the fix is a 1-line change.

## Version

`v2026.1.24-3`

## Comments

### @andrew-kurin (2026-01-26)

Experiencing this as well. Running with `softThresholdTokens: 100000` on Opus 4.5 (200k context), yet compaction still fires with "Summary unavailable due to context limits" — the session loses all prior context.

The analysis here matches what we're seeing: the token count check doesn't account for output tokens + new message, so the flush never triggers in time.

The proposed fix (adding `outputTokens` to the check) makes sense. Would also be worth considering #1644's suggestion to prune tool results before compaction — our sessions often have large tool outputs (file reads, exec results) that probably shouldn't consume the `keepRecentTokens` budget over actual conversation.

### @plandrem (2026-01-27)

I've also lost context when running `/new`. Seems like that should trigger memory consolidation. I could also see commiting context to memory whenever the user is inactive for ~20 minutes


## Links

- None detected yet

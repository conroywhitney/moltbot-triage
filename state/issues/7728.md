---
number: 7728
title: "ollama-cloud models minimax-m2.1 and glm-4.7 complete runs but return no response to Telegram"
author: dkingfx
created: 2026-02-03T04:44:12Z
updated: 2026-02-03T04:44:12Z
labels: []
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/7728
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Bug Description

When using ollama-cloud provider with models `minimax-m2.1` or `glm-4.7`, the agent run completes successfully but no response is delivered to Telegram.

## Environment
- OpenClaw version: 2026.2.1
- Channel: Telegram
- Provider: ollama-cloud
- Affected models: `minimax-m2.1`, `glm-4.7`
- Working model: `kimi-k2.5` (same provider)

## Steps to Reproduce
1. Configure ollama-cloud provider with API key
2. Set primary model to `ollama-cloud/minimax-m2.1` or `ollama-cloud/glm-4.7`
3. Add model to `agents.defaults.models` allowlist
4. Send a message via Telegram

## Expected Behavior
Model responds and message is delivered to Telegram.

## Actual Behavior
- Logs show `embedded run start` and `embedded run done` with ~2.5s duration
- No errors in logs
- No message delivered to Telegram
- Run completes with `aborted=false`

## Additional Context
- Direct API test to ollama.com/v1/chat/completions with same models returns valid responses
- `kimi-k2.5` on same provider works correctly
- Tried both `streamMode: partial` and `streamMode: block` - same result

## Logs
```
embedded run start: runId=xxx provider=ollama-cloud model=minimax-m2.1 thinking=off messageChannel=telegram
embedded run done: runId=xxx durationMs=2660 aborted=false
```

No Telegram send/deliver logs appear after run completion.

## Comments


## Links

- None detected yet

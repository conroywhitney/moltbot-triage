---
number: 3613
title: "Feature: Expose compaction events to hook system"
author: akolselim
created: 2026-01-28T22:37:12Z
updated: 2026-01-28T22:37:12Z
labels: []
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/moltbot/moltbot/issues/3613
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

When context window fills up and auto-compaction triggers, there's no way for hooks to react to this event. The compaction events (`auto_compaction_start`, `auto_compaction_end`) are emitted via `emitAgentEvent()` but are not connected to the hook system (`triggerInternalHook()`).

## Use Case

I'm building a document processing pipeline that reads large legal documents (30-50 pages). When processing long documents, the context can fill up unexpectedly, causing data loss before I can persist important extracted text to files.

Having a `session:compaction_start` or `session:context_warning` hook would allow:
- Flushing accumulated data to disk before compaction
- Logging/alerting when context is getting full
- Graceful handling of long document processing

## Proposed Solution

Add `triggerInternalHook()` calls in `pi-embedded-subscribe.handlers.lifecycle.js`:

```javascript
// In handleAutoCompactionStart()
await triggerInternalHook({
    type: 'session',
    action: 'compaction_start',
    sessionKey: ctx.params.sessionKey,
    timestamp: new Date(),
    messages: [],
    context: { runId: ctx.params.runId }
});

// In handleAutoCompactionEnd()
await triggerInternalHook({
    type: 'session',
    action: 'compaction_end',
    sessionKey: ctx.params.sessionKey,
    timestamp: new Date(),
    messages: [],
    context: { 
        runId: ctx.params.runId,
        willRetry: evt.willRetry 
    }
});
```

## Alternatives Considered

1. **Skill-level monitoring**: Manually tracking character counts in skills - works but fragile
2. **Local patch**: Patching dist files directly - not maintainable

## Additional Context

This would also enable a `session:context_warning` event (e.g., at 80% capacity) which would be even more useful for proactive data persistence.

Happy to submit a PR if this approach looks good!

## Comments


## Links

- None detected yet

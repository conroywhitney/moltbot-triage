---
number: 6137
title: "[Bug]: Unable to configure  Agent endpoint for local Nvidia DGX Spark execution"
author: donutloop
created: 2026-02-01T09:51:18Z
updated: 2026-02-01T09:51:18Z
labels: ["bug"]
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/6137
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

What went wrong?

I am unable to configure OpenClaw to utilize an existing, locally running agent hosted on an NVIDIA DGX Spark (https://www.nvidia.com/en-us/products/workstations/dgx-spark/). While the agent service is running correctly on the Spark syste, OpenClaw appears to lack the necessary configuration options (or documentation) to point the orchestration engine to my locally running agent????

To Reproduce Steps to reproduce the behavior:

- Deploy an agent model instance via ollama on a local NVIDIA DGX desktop.
- Install/Initialize OpenClaw.
- Attempt to configure the agent connection between Openclaw and with my local Agent on my local NVIDIA DGX desktop.
- Issue: No menu option for local agents configurations (Or no obvious one)
- Result: I'm trying to discover options after some time passed I begin looping in the menu or in the internet.

## Expected behavior

What did you expect to happen?

OpenClaw connects with any local runable and compatible AI model. 

## Actual behavior

What actually happened?

OpenClaw can't connect to local  AI models.

## Environment

- Clawdbot version: Latest
- OS: Nvidia DGX OS
- Install method (pnpm/npx/docker/etc): Installer from official website

## Logs or screenshots

Paste relevant logs or add screenshots (redact secrets).

## Comments


## Links

- None detected yet

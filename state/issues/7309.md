---
number: 7309
title: "[Feature]: Support DeepSeek API as a first-class LLM provider"
author: farazoman
created: 2026-02-02T17:32:26Z
updated: 2026-02-02T17:32:26Z
labels: ["enhancement"]
assignees: []
comments_count: 0
reactions_total: 2
url: https://github.com/openclaw/openclaw/issues/7309
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

Many users now have access to DeepSeek's OpenAI-compatible API and would like to use DeepSeek models directly in OpenClaw, without confusing the setup flow or manually hacking config files.

Currently, onboarding and provider selection do not offer an explicit "DeepSeek" provider. Users are not sure whether to pick "OpenAI", and adding a custom provider requires manual editing of config, with uncertainty about the correct baseUrl, API type, and model id fields.

## Proposed solution

- Add built-in provider support for DeepSeek API:
  - Recognize DeepSeek as a provider with a dedicated onboarding step (similar to OpenAI, Anthropic, etc.)
  - Where possible, pre-fill the correct API type ("openai-completions"), accept API key, and let user specify DeepSeek's baseUrl and model(s).
  - Update the default onboarding flow and docs to mention DeepSeek if a user pastes a DeepSeek key or baseUrl.
- Add an entry in the config generator wizard for DeepSeek API with:
  - `provider: deepseek`
  - `baseUrl`: user input (e.g. `https://api.deepseek.com/v1`)
  - `apiKey`: user input or `${DEEPSEEK_API_KEY}`
  - `api`: `openai-completions`
  - Allow normal `provider/model` selection (e.g. `deepseek/deepseek-chat` or whatever models are supported)
- Document this provider in the README and onboarding instructions, with an explicit working example config for DeepSeek API users.

## Alternatives considered

- Have users select "OpenAI" as provider and override baseUrl manually in config (works but is confusing/misleading; does not scale to onboarding for new users)
- Use existing "custom provider" support, requiring deep documentation and manual config editing

## Additional context

- This request is based on real user onboarding confusion. See a detailed workflow and config example below for DeepSeek integration:

```json5
{
  env: {
    DEEPSEEK_API_KEY: "sk-..."
  },
  models: {
    mode: "merge",
    providers: {
      deepseek: {
        baseUrl: "https://api.deepseek.com/v1",
        apiKey: "${DEEPSEEK_API_KEY}",
        api: "openai-completions",
        models: [
          {
            id: "deepseek-chat",
            name: "DeepSeek Chat",
            api: "openai-completions",
            reasoning: false,
            input: ["text"],
            cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
            contextWindow: 128000,
            maxTokens: 8192
          }
        ]
      }
    }
  },
  agents: {
    defaults: {
      model: {
        primary: "deepseek/deepseek-chat"
      }
    }
  }
}
```

- More context in [this discussion](https://github.com/openclaw/openclaw/discussions) and AI support channels.
- See also the behavior of the Copilot Proxy provider implementation, which makes onboarding of OpenAI-compatible endpoints smooth.

Thank you for considering and helping new users onboard seamlessly with DeepSeek!

## Comments


## Links

- None detected yet

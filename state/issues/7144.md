---
number: 7144
title: "session_status shows requested model instead of actual running model after failover"
author: ewijaya
created: 2026-02-02T12:56:29Z
updated: 2026-02-02T12:56:29Z
labels: []
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/7144
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary
`session_status` (and the tool that powers `/session_status`) reports the **requested** model rather than the **actually running** model when a failover occurs.

## Steps to Reproduce
1. Configure a primary model (e.g., `openai-codex/gpt-5.2`) that has no API key
2. Have a fallback configured (e.g., `anthropic/claude-opus-4-5`)
3. Start a session - it will fail over to the fallback
4. Run `/session_status` or use the `session_status` tool

## Expected Behavior
Should show: `anthropic/claude-opus-4-5` (the model actually handling requests)

## Actual Behavior
Shows: `openai-codex/gpt-5.2` (the model that was requested but failed)

## Evidence
Gateway logs show the failover and actual model:
```
ERROR: No API key found for provider "openai-codex"
embedded run start: provider=anthropic model=claude-opus-4-5
```

But `session_status` returns:
```
ðŸ§  Model: openai-codex/gpt-5.2
```

## Additional Context
- The TUI correctly shows the configured default model
- This creates confusion about which model is actually running
- Version: OpenClaw 2026.2.1 (ed4529e)

## Comments


## Links

- None detected yet

---
number: 5999
title: "[Bug]: Heartbeats Broken. Infinite HTTP 400 Exceeded Context Length Errors."
author: trevtravtrev
created: 2026-02-01T05:38:03Z
updated: 2026-02-01T05:39:25Z
labels: ["bug"]
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/5999
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Summary

OpenClaw repeatedly sends heartbeat requests that exceed the model’s maximum context length (~202,750 tokens), resulting in an infinite continuous HTTP 400 errors and a retry loop instead of graceful handling and heartbeats no longer working until gateway restarted.

## Steps to reproduce

1. Run clawdbot heartbeats continuously every 30m.
2. Use Z.ai GLM4.7
3. Have a heartbeats.md that specifies some tasks to do occasionally.
4. Observe requests sent to the model exceeding its max context window.

## Expected behavior

- OpenClaw should detect when the prompt/context exceeds the model’s max token limit.
- It should automatically compact or handle gracefully.

## Actual behavior

- Infinite consecutive HTTP 400 errors:
- `Request XXXXX input tokens exceeds the model's maximum context length 202750`
- Even though it only shows tokens 128k/205k on every repeated request
- The agent continues retrying heartbeats with growing token counts.
- System remains connected but effectively stalled forever and no heartbeats work (`gateway connected | idle`).

## Environment

- Clawdbot version: OpenClaw 1.30 and ClawdBot 1.24
- OS: Ubuntu Linux

## Logs or screenshots
 Read HEARTBEAT.md if it exists (workspace context). Follow it strictly. Do not infer or repeat old tasks from prior
 chats. If nothing needs attention, reply HEARTBEAT_OK.
HTTP 400: Invalid API parameter. Request 137814 input tokens exceeds the model's maximum context length 202750
 Read HEARTBEAT.md if it exists (workspace context). Follow it strictly. Do not infer or repeat old tasks from prior
 chats. If nothing needs attention, reply HEARTBEAT_OK.
HTTP 400: Invalid API parameter. Request 137855 input tokens exceeds the model's maximum context length 202750
 Read HEARTBEAT.md if it exists (workspace context). Follow it strictly. Do not infer or repeat old tasks from prior
 chats. If nothing needs attention, reply HEARTBEAT_OK.
HTTP 400: Invalid API parameter. Request 137896 input tokens exceeds the model's maximum context length 202750
 Read HEARTBEAT.md if it exists (workspace context). Follow it strictly. Do not infer or repeat old tasks from prior
 chats. If nothing needs attention, reply HEARTBEAT_OK.
HTTP 400: Invalid API parameter. Request 137937 input tokens exceeds the model's maximum context length 202750
 Read HEARTBEAT.md if it exists (workspace context). Follow it strictly. Do not infer or repeat old tasks from prior
 chats. If nothing needs attention, reply HEARTBEAT_OK.
HTTP 400: Invalid API parameter. Request 137978 input tokens exceeds the model's maximum context length 202750
 Read HEARTBEAT.md if it exists (workspace context). Follow it strictly. Do not infer or repeat old tasks from prior
 chats. If nothing needs attention, reply HEARTBEAT_OK.
HTTP 400: Invalid API parameter. Request 138019 input tokens exceeds the model's maximum context length 202750
 Read HEARTBEAT.md if it exists (workspace context). Follow it strictly. Do not infer or repeat old tasks from prior
 chats. If nothing needs attention, reply HEARTBEAT_OK.
HTTP 400: Invalid API parameter. Request 138060 input tokens exceeds the model's maximum context length 202750
 gateway connected | idle
 agent main | session main | zai/glm-4.7 | tokens 128k/205k (63%)

## Comments


## Links

- None detected yet

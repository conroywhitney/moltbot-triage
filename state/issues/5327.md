---
number: 5327
title: "Audio: raw binary injected into context after successful transcription"
author: JustTrott
created: 2026-01-31T10:38:11Z
updated: 2026-02-02T00:19:34Z
labels: ["bug"]
assignees: []
comments_count: 1
reactions_total: 1
url: https://github.com/openclaw/openclaw/issues/5327
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Problem

When a voice message is received and successfully transcribed via CLI STT (parakeet/sherpa-onnx), the raw audio binary (OGG/Opus) is **still injected into the model context** alongside the transcript. The binary bytes render as CJK/garbage characters and consume massive amounts of context tokens.

A short 10-second voice message adds ~15KB of binary garbage to context. A 40-second voice causes context overflow and triggers safeguard compaction, effectively crashing the session.

## Expected behavior

After successful audio transcription, the raw audio binary should **not** be passed to the model — only the transcript text. Claude (and most text models) cannot process raw OGG binary, so it's pure context waste.

## Suggested fix

Add a config option like `tools.media.audio.stripRawOnSuccess: true` (or make it the default) that removes the raw audio attachment from the model context when transcription succeeds. The current behavior (`Preserve original media delivery to the model (always)`) makes sense for images (vision models can use them) but not for audio with text-only models.

## Reproduction

1. Configure CLI-based audio transcription (e.g., parakeet-stt via sherpa-onnx)
2. Send a voice message via Telegram
3. Observe webchat — raw binary appears as Chinese/CJK characters in the message
4. Send a longer voice (40+ seconds) — context overflows and compacts

## Environment

- OpenClaw 2026.1.29
- Model: Claude Opus 4.5 (text-only, no native audio input)
- STT: parakeet-stt (sherpa-onnx, CLI type)
- Channel: Telegram

## Comments

### @Glucksberg (2026-01-31)

This issue appears to be caused by the same root cause as #5330, and will be resolved by PR #5376.

**Root cause:**

In `src/media-understanding/apply.ts`, the `extractFileBlocks` function has this condition:

```typescript
if (!forcedTextMimeResolved && kind === "audio" && !textLike) {
  continue;
}
```

The problem is that OGG/Opus files contain ~40% null bytes in their headers, which causes `resolveUtf16Charset()` to misidentify them as UTF-16 text (`textLike = true`). This means the `continue` never executes, and the binary is decoded as "text" and injected into the context — even when STT transcription succeeds.

**Why the binary appears alongside the transcript:**

1. `extractFileBlocks` runs first and adds the garbage "text" to `fileBlocks`
2. `runCapability` (transcription) runs in parallel
3. Both results are appended to `ctx.Body` — the transcript via `formatMediaUnderstandingBody`, and the garbage via `appendFileBlocks`

**Fix in #5376:**

```diff
- if (!forcedTextMimeResolved && kind === "audio" && !textLike) {
+ if (!forcedTextMimeResolved && (kind === "audio" || kind === "video")) {
```

This ensures audio/video files are always handled by the STT/description pipeline, never the text extraction path — regardless of byte patterns.

This appears to be a duplicate of #5330, tracked by PR #5376.


## Links

- None detected yet

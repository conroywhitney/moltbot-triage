---
number: 4499
title: "bug(tui): MiniMax responses show '(no output)' until TUI restart"
author: bee4come
created: 2026-01-30T08:26:12Z
updated: 2026-02-01T21:29:10Z
labels: ["bug"]
assignees: []
comments_count: 7
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/4499
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Description

When using MiniMax models (e.g., `minimax-cn/MiniMax-M2.1`) in the TUI, responses display as `(no output)` even though the model returns content successfully. The same responses display correctly in Telegram.

## Steps to Reproduce

1. Configure MiniMax as a provider with valid API key
2. Set model to `minimax-cn/MiniMax-M2.1` (via `/model m2cn` or config)
3. Send a message in the TUI
4. Observe: TUI shows `(no output)`
5. Check Telegram: Same message displays correctly
6. Restart TUI
7. Observe: Now historical responses display correctly

## Expected Behavior

MiniMax responses should render immediately in the TUI without requiring a restart.

## Actual Behavior

- TUI shows `(no output)` for MiniMax responses
- Telegram renders the same responses correctly
- Restarting TUI fixes the display issue retroactively

## Possible Cause

The TUI may be expecting Anthropic-specific response format or handling streaming differently for non-Anthropic providers. MiniMax uses an Anthropic-compatible API but may have slight format differences in the response structure.

From session logs, MiniMax returns:
```json
{
  "thinking": "...",
  "text": "..."
}
```

The TUI might not be parsing the `text` field correctly for MiniMax responses during live streaming, but handles it correctly when loading from transcript on restart.

## Environment

- OpenClaw version: latest
- Channel: TUI + Telegram
- Provider: minimax-cn
- Model: MiniMax-M2.1

## Comments

### @Kingtous (2026-01-30)

same here

### @bee4come (2026-01-30)

## 调查更新

经过详细测试，发现一个奇怪的现象：

### 测试结果
| 环境 | MiniMax 响应 |
|------|-------------|
| Docker 官方镜像 (ghcr.io/openclaw/openclaw:latest) | ✅ 正常 |
| 源码编译 (git clone + pnpm build) | ✅ 正常 |
| npm 全局安装 (npm install -g openclaw) | ❌ (no output) |

### 验证的内容
- OpenClaw 版本: 都是 2026.1.29
- `provider-utils.js` MD5: 相同
- `tui-formatters.js` MD5: 相同  
- `tui-stream-assembler.js` MD5: 相同
- `@mariozechner/pi-ai` 版本: 都是 0.49.3

### 配置测试
- 使用 `api: anthropic-messages` + `baseUrl: api.minimaxi.com/anthropic`: ❌ 失败
- 使用 `baseUrl: api.minimax.chat/v1` (无 api 字段): ❌ 同样失败

### 日志对比
两边的 gateway 日志结构相同，都显示 `aborted=false` 成功完成。问题似乎在 TUI 渲染层，而不是 API 调用层。

### 未解之谜
代码完全相同，但 npm 安装版本有问题，Docker/源码版本正常。可能是：
1. npm 发布过程中的某些差异
2. 运行时状态/缓存问题
3. 需要更深入的调试

重新打开 PR #4526 可能仍然是正确的方向（从 `isReasoningTagProvider` 移除 MiniMax），因为 `enforceFinalTag` 逻辑确实可能导致此问题。

### @Tony-Lee (2026-01-30)

Same problem here 

### @Cojad (2026-01-30)

I can confirm that below commit fixed the problem for TUI.
TUI is now working again for minimax
https://github.com/srozov/clawdbot/commit/c3f5b9e5600a4ce76d1552000c60aba80bc0bd80

### @murTorun (2026-01-31)

Ctrl+T seems to be a temporary fix, instead of restarting the TUI.

### @jeeyongx (2026-01-31)

同样的问题. 尝试在多台主机中测试.
配置文件为最小配置, 只配置了MiniMax M2.1模型.
尝试MiniMax, MiniMax-cn.
尝试变更api类型 anthropic-messages / openai-completions
都会出现以上问题.
安装方式是openclaw提供的一键脚本及npm全局安装.
版本信息:
openclaw: 2026.1.29


### @AndrewGerstenslager (2026-02-01)

Same thing is happening with local ollama models. The web ui shows it works but then I also get (no response) when any local endpoint is hit on windows


## Links

- None detected yet

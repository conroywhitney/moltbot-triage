---
number: 4197
title: "Feature: Strip raw audio attachment after successful transcription"
author: nobrainer-tech
created: 2026-01-29T21:13:53Z
updated: 2026-01-29T21:34:46Z
labels: []
assignees: []
comments_count: 1
reactions_total: 2
url: https://github.com/openclaw/openclaw/issues/4197
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Problem

When audio understanding (transcription) succeeds, Moltbot correctly:
1. Replaces `Body` with an `[Audio]` block containing the transcript
2. Sets `{{Transcript}}` for command parsing

However, the **raw audio binary file is still passed as an attachment** to the model alongside the transcript. This means every voice message includes both:
- ✅ The useful transcript text
- ❌ The raw OGG/Opus binary blob in a `<file>` block

From the docs: *"Attachments are still passed to models even when understanding is disabled."*

There is currently **no config option** to strip the raw attachment after a successful transcription.

## Impact

### Token waste per message
A typical 10-second Telegram voice message (~15-20KB OGG) generates a `<file>` block like:
```
<file name="file_49---xxxx.ogg" mime="text/plain">
杏卧Ȁ    ៥뎫  䰁㲹ጁ灏獵效摡āĸ뮀  伀杧S    ꬗Ƴ...
[~500-2000 lines of binary garbage characters]
</file>
```
This binary data is **completely useless** to the model — it cannot interpret raw OGG/Opus bytes — yet it consumes **hundreds to thousands of tokens** per message.

### Long voice messages are effectively broken
Longer voice messages (30s+, 1min+) produce proportionally larger binary blobs. A **1-minute voice message** can generate **50-100KB of raw binary** in the model context. This:
- Rapidly fills the context window
- Can cause context overflow errors in shorter-context models
- Makes it **impractical to send longer voice messages**, even though the transcript itself is just a few sentences

### What the model actually sees in logs
The model receives something like:
```
[Audio] User text: Transcript: "Okej, sprawdź mi proszę..."

<file name="file_49---ef227a48.ogg" mime="text/plain">
杏卧Ȁ    ៥뎫  䰁㲹ጁ灏獵效摡āĸ뮀  伀杧S
꬗Ƴ 䜀覇Ϳ￿俾異味条൳ 氀扩灯獵ㄠ㔮ㄮ
[... hundreds more lines of binary ...]
伀杧S耀»  ꬗ʳ 頀㊬̃偍䥑慢晚乎
[... continues for the entire file ...]
</file>
```

The transcript is **a single line**. The binary blob is **hundreds of lines**. The ratio of useful content to waste can be 1:100 or worse.

### Cumulative context damage
In a conversation with multiple voice messages, the context fills up with binary garbage. After just 3-5 voice messages, a significant portion of the context window is consumed by useless binary data, pushing out actual conversation history.

## Cost estimate
- ~500-2000 tokens wasted per short voice message (10-15s)
- ~2000-8000+ tokens wasted per longer voice message (30s-1min)
- On Claude Opus: ~$0.01-0.10+ per voice message in wasted input tokens
- Multiplied across a conversation with many voice messages, this adds up significantly

## Proposed Solution

Add a config option under `tools.media.audio`:

```json5
{
  tools: {
    media: {
      audio: {
        stripAfterTranscript: true  // default: false (backward compatible)
      }
    }
  }
}
```

When `stripAfterTranscript: true` and transcription succeeds:
- Remove the original audio attachment from the model context
- Keep only the `[Audio]` block with the transcript text
- If transcription fails, fall back to current behavior (pass raw attachment)

Alternative: make this the **default behavior** — there is no use case where the model benefits from seeing raw OGG binary bytes when a transcript is already available.

## Environment

- **Channel**: Telegram (voice messages as OGG/Opus)
- **Transcription**: CLI whisper-cpp (local, works perfectly)
- **Models**: Claude Opus 4.5 / Sonnet 4.5
- **Version**: 2026.1.27-beta.1

## Comments

### @SMBarreraH (2026-01-29)

looks cool.


## Links

- None detected yet

---
number: 7200
title: "Feature Request: Real-time Voice Conversation Support"
author: miefriglapicioare-web
created: 2026-02-02T14:54:47Z
updated: 2026-02-02T21:10:50Z
labels: []
assignees: []
comments_count: 1
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/7200
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

# Summary
Add native support for real-time voice conversations (bidirectional streaming audio) to enable phone-like interactions via Twilio/WebRTC integration.

## Motivation / Use Case
Currently, OpenClaw supports text messaging and voice messages (pre-recorded audio files). However, many users want to have fluid, real-time voice conversations with their AI assistant - similar to ChatGPT Voice or Gemini Live.

**Specific use case:**
- User self-hosts OpenClaw on a dedicated server with sufficient resources
- User has set up local TTS (e.g., edge-tts with a high-quality custom voice)
- User wants to call a Twilio number and have a natural, real-time voice conversation
- Current limitation: Only pre-recorded voice messages are supported, not streaming

## Proposed Solution

### Option A: Twilio Media Streams Integration
Integrate with [Twilio Media Streams](https://www.twilio.com/docs/voice/twiml/stream) to handle bidirectional audio streaming:


User Phone <--> Twilio <--> WebSocket <--> OpenClaw
                    ↓
              Real-time pipeline:
              1. Audio stream → STT (Whisper streaming)
              2. LLM generates response
              3. TTS generates audio (local edge-tts or similar)
              4. Audio stream back to user


**Technical requirements:**
- WebSocket server for audio streaming
- Real-time STT (OpenAI Whisper streaming or similar)
- Streaming LLM responses
- Fast TTS with caching (local edge-tts)
- Interruption handling (user can speak over AI)

### Option B: WebRTC Native Support
Add WebRTC support for browser-based voice calls without Twilio.

### Option C: Voice "Voicemail" Mode (MVP)
Intermediate solution:
1. User calls Twilio number
2. AI speaks first (pre-generated greeting)
3. User records message
4. Call ends
5. AI processes, generates response
6. AI calls user back with response

## Current Setup Reference
- Server: Self-hosted dedicated server (e.g., 64GB RAM, NVMe SSD)
- TTS: edge-tts-as-a-service running locally
- Voice: High-quality local TTS voice
- Channel: WhatsApp (working)
- Goal: Add Twilio voice with local TTS quality

## Benefits
1. **Accessibility**: Users can talk hands-free while driving, cooking, etc.
2. **Natural interaction**: Voice is more natural than text for many use cases
3. **Self-hosted**: Unlike ChatGPT Voice, data stays on user's server
4. **Custom voices**: Use local TTS with personalized voices
5. **Cost effective**: Self-hosted vs. paying for ChatGPT Plus ($20/month)
6. **Language support**: Local TTS supports languages cloud providers don't cover well

## Potential Challenges
1. **Latency**: Need < 500ms total pipeline latency for natural feel
2. **STT streaming**: Need real-time transcription, not batch
3. **Interruptions**: Complex to handle user interrupting AI mid-sentence
4. **Audio codecs**: Twilio uses specific formats (μ-law, Opus)
5. **Resource usage**: Real-time streaming requires significant CPU/RAM

## Alternatives Considered
- **ChatGPT Voice**: Proprietary, cloud-based, no custom voices
- **Gemini Live**: Same limitations
- **Current voice messages**: Not real-time, requires manual recording/sending

## Additional Context
I have a working setup with edge-tts-as-a-service API running locally. The TTS quality is excellent. Now I need the "glue" to connect Twilio voice calls to this local TTS + LLM pipeline.

## Related Issues
None found for real-time voice/streaming.

## Comments

### @AkashaBot (2026-02-02)

This is a great request — and we’re actually pretty close today via the built-in voice-call plugin.

### Option A (Twilio Media Streams) is already the direction
OpenClaw’s voice-call plugin supports Twilio webhooks and a streaming endpoint (bidirectional audio over WebSocket), which maps directly to “Phone <-> Twilio <-> WebSocket <-> OpenClaw”.

High-level flow:
- Twilio call hits /voice/webhook (TwiML)
- TwiML starts a <Stream> to /voice/stream
- OpenClaw runs a realtime loop: STT → LLM → TTS → stream back, with interruption (barge‑in) handling

### What’s still missing / what we can improve
- Documentation: end-to-end Twilio setup + example TwiML + troubleshooting
- UX: one-command “enable voice streaming” wizard + health checks
- Optional: WebRTC as a separate browser-native mode (nice-to-have)

If you can share:
- your target latency budget and codec preferences (μ-law vs Opus)
- which STT you want to use (OpenAI Realtime, Whisper streaming, etc.)

…we can turn this into a concrete doc page + small PR to make it easier to self-host.


## Links

- None detected yet

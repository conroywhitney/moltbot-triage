---
number: 6870
title: "System prompt (SOUL.md, IDENTITY.md) not passed to custom openai-completions providers"
author: wydyydlhb1990
created: 2026-02-02T04:24:17Z
updated: 2026-02-02T04:24:17Z
labels: []
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/6870
duplicate_of: null
related_issues: [4028,4857,4916]
blocks: []
blocked_by: []
---

## Description

## Description

When using a custom provider configured with `api: "openai-completions"`, the system prompt (including SOUL.md, IDENTITY.md, and other bootstrap files) is not properly passed to the provider endpoint. The agent responds without its configured identity/personality.

## Environment

- OpenClaw version: 2026.1.30
- OS: macOS Darwin 25.2.0
- Custom provider: claude-max-api-proxy (OpenAI-compatible wrapper for Claude Code CLI)

## Configuration

```json
{
  "models": {
    "providers": {
      "claude-max": {
        "baseUrl": "http://localhost:3456/v1",
        "apiKey": "not-needed",
        "api": "openai-completions",
        "models": [
          {
            "id": "claude-sonnet-4",
            "name": "Claude Sonnet 4",
            "input": ["text"],
            "contextWindow": 200000,
            "maxTokens": 8192
          }
        ]
      }
    }
  },
  "agents": {
    "defaults": {
      "model": { "primary": "claude-max/claude-sonnet-4" }
    }
  }
}
```

## Steps to Reproduce

1. Configure a custom provider with `api: "openai-completions"` pointing to an OpenAI-compatible endpoint
2. Set it as the default model
3. Have SOUL.md and IDENTITY.md configured in the workspace
4. Run: `openclaw agent --local --agent main --message "What is your name?"`

## Expected Behavior

The agent should respond according to its IDENTITY.md (e.g., "I'm 瓜豆机") and follow the personality defined in SOUL.md.

## Actual Behavior

The agent ignores SOUL.md and IDENTITY.md entirely, responding as a generic assistant without personality. The `systemPromptReport` in JSON output shows the files ARE being loaded (49,791 chars), but they're not being sent to the custom provider.

## Verification

When calling the same provider endpoint directly with curl and including a system message, it works correctly:

```bash
curl -X POST http://localhost:3456/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4",
    "messages": [
      {"role": "system", "content": "You are 瓜豆机..."},
      {"role": "user", "content": "What is your name?"}
    ]
  }'
# Response correctly includes identity
```

This confirms the issue is in how OpenClaw constructs/sends requests to `openai-completions` providers, not the provider itself.

## Related Issues

- #4028 - Ollama context truncation (similar bootstrap file issue)
- #4857 - Custom providers crash (fixed in PR #4916)

## Possible Cause

The `openai-completions` API path may not be including the system prompt as a `system` role message in the request body. Built-in providers likely use a different code path that handles this correctly.

## Suggested Fix

Ensure that when constructing requests for `openai-completions` providers, the system prompt is included as a message with `role: "system"` in the messages array.

## Comments


## Links

- None detected yet

---
number: 3153
title: "Ollama provider crashes with 'Unhandled API in mapOptionsForApi: undefined'"
author: nesnewsnad
created: 2026-01-28T05:23:40Z
updated: 2026-01-28T05:54:20Z
labels: ["bug"]
assignees: []
comments_count: 1
reactions_total: 1
url: https://github.com/moltbot/moltbot/issues/3153
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Environment
- Clawdbot version: 2026.1.24-3
- Node: 22.22.0
- OS: Ubuntu Linux 6.8.0-71-generic (x64)
- Ollama: Running on remote host via Tailscale (baseUrl configured)

## Configuration
```json
{
  "models": {
    "providers": {
      "ollama": {
        "baseUrl": "http://100.x.x.x:11434/v1",
        "apiKey": "ollama-local",
        "models": [
          {"name": "qwen2.5-coder:14b", "id": "qwen2.5-coder:14b"}
        ]
      }
    }
  },
  "agents": {
    "defaults": {
      "model": {
        "primary": "ollama/qwen2.5-coder:14b",
        "fallbacks": ["anthropic/claude-opus-4-5"]
      }
    }
  }
}
```

## Steps to Reproduce
1. Configure Ollama provider with remote baseUrl
2. Set Ollama model as primary
3. Send a message via Telegram

## Error
```
2026-01-28T04:53:51.841Z debug agent/embedded embedded run start: runId=... provider=ollama model=qwen2.5-coder:14b
2026-01-28T04:53:52.193Z error [clawdbot] Uncaught exception: Error: spawn docker ENOENT
```

After installing Docker:
```
2026-01-28T05:08:56.251Z [clawdbot] Unhandled promise rejection: Error: Unhandled API in mapOptionsForApi: undefined
    at mapOptionsForApi (file:///usr/lib/node_modules/clawdbot/node_modules/@mariozechner/pi-ai/src/stream.ts:471:10)
    at streamSimple (file:///usr/lib/node_modules/clawdbot/node_modules/@mariozechner/pi-ai/src/stream.ts:218:26)
    at streamAssistantResponse (file:///usr/lib/node_modules/clawdbot/node_modules/@mariozechner/pi-agent-core/src/agent-loop.ts:233:25)
    at runLoop (file:///usr/lib/node_modules/clawdbot/node_modules/@mariozechner/pi-agent-core/src/agent-loop.ts:141:20)
```

## Expected Behavior
Clawdbot should successfully route requests to the Ollama provider.

## Notes
- Ollama API is reachable from the VPS (verified with `curl`)
- Models are correctly listed via `/api/tags`
- Gateway crashes and becomes unresponsive after the error

## Comments

### @a289459798 (2026-01-28)

感谢您提供的详细错误信息！这个错误 "Unhandled API in mapOptionsForApi: undefined" 表明Ollama提供商在处理API映射时遇到了未定义的API类型。

根据错误堆栈，问题出现在 pi-ai 库的 stream.ts 文件中。这很可能是由于：

1. Ollama API 返回了一个未知的响应格式
2. 配置中的某些参数未正确传递给Ollama

请尝试以下解决方案：

1. 验证Ollama配置：
{
  "models": {
    "providers": {
      "ollama": {
        "baseUrl": "http://100.x.x.x:11434",
        "apiKey": "ollama-local",
        "models": [
          {"name": "qwen2.5-coder:14b", "id": "qwen2.5-coder:14b"}
        ],
        "options": {
          "temperature": 0.7,
          "top_p": 0.9
        }
      }
    }
  }
}

2. 检查远程Ollama服务器状态：
curl http://100.x.x.x:11434/api/tags

3. 确保Ollama版本兼容性 - 某些较新的Ollama版本可能引入了API变化

4. 临时解决方案：在配置中添加一个备用模型：
{
  "agents": {
    "defaults": {
      "model": {
        "primary": "ollama/qwen2.5-coder:14b",
        "fallbacks": ["anthropic/claude-sonnet-4-5"]
      }
    }
  }
}

我们会在下一个版本中加强Ollama提供商的错误处理，以更好地处理这类API映射错误。


## Links

- None detected yet

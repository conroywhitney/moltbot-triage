---
number: 4043
title: "Stale session write locks persist after SIGUSR1 in-process restart (PID 1 containers)"
author: seanb4t
created: 2026-01-29T15:44:56Z
updated: 2026-01-29T15:44:56Z
labels: []
assignees: []
comments_count: 0
reactions_total: 0
url: https://github.com/moltbot/moltbot/issues/4043
duplicate_of: null
related_issues: []
blocks: []
blocked_by: []
---

## Description

## Bug Description

After an in-process restart via SIGUSR1, on-disk session write lock files (`.lock`) persist and block session access for up to 30 minutes (`staleMs`).

## Root Cause

Session write locks in `src/agents/session-write-lock.ts` store `{ pid, createdAt }` on disk. On SIGUSR1, the gateway restarts in-place via the run-loop (`src/cli/gateway-cli/run-loop.ts`) — same process, same PID.

The in-memory `HELD_LOCKS` Map is effectively cleared when the old server instance shuts down, but the on-disk `.lock` files survive. When the new server iteration starts:

1. Lock file exists with PID 1
2. `isAlive(1)` returns `true` (same process)
3. `createdAt` is recent (not stale)
4. Lock appears valid → session access blocked for up to 30 minutes

This is particularly common in containers where PID = 1.

## Impact

- Users cannot access sessions for up to 30 minutes after a config change or gateway restart
- Gateway cron RPC may timeout due to lock contention
- Manual workaround required: `find /home/node/.clawdbot -name "*.lock" -delete`

## Expected Behavior

Session locks should be released during shutdown and any surviving locks should be detectable as stale by the next server iteration.

## Environment

- Container runtime (PID 1)
- SIGUSR1 in-process restart via `runGatewayLoop`
- ESM module cache persists across restart iterations (modules are not re-evaluated)

## Comments


## Links

- None detected yet

---
number: 4544
title: "[Bug]: Cannot change model to Ollama Deepseek-r1:latest"
author: shivanraptor
created: 2026-01-30T09:24:12Z
updated: 2026-01-31T13:03:19Z
labels: ["bug"]
assignees: []
comments_count: 3
reactions_total: 0
url: https://github.com/openclaw/openclaw/issues/4544
duplicate_of: null
related_issues: [1]
blocks: []
blocked_by: []
---

## Description

## Summary
What went wrong?
Tried to ask via Chat (original model is Qwen) to change to local Ollama's deepseek-r1:latest, which is already pulled and verified.

## Steps to reproduce
1. Installed Ollama and run `ollama pull deepseek-r1:latest`
2. Ask in chat to change the default model to DeepSeek (also tried Llama3.3, same problem)
3. The model cannot be changed. In CLI, I run `openclaw model list`, it reports:
```
% openclaw models list        

ðŸ¦ž OpenClaw 2026.1.29 (a5b4d22) â€” One CLI to rule them all, and one more restart because you changed the port.

Model                                      Input      Ctx      Local Auth  Tags
ollama/deepseek-r1:latest                  -          -        -     -     default,missing
qwen-portal/vision-model                   text+image 125k     no    yes   fallback#1,configured
qwen-portal/coder-model                    text       125k     no    yes   configured,alias:qwen
```
It said the Ollama Deepseek is missing.

## Expected behavior
What did you expect to happen?
Expect the model changed and restart the gateway, then everything is fine.

## Actual behavior
What actually happened?
The chat stops responding afterwards.

## Environment
- Clawdbot version: 2026.1.29
- OS: macOS Tahoe 26.2
- Install method (pnpm/npx/docker/etc): `npm install -g openclaw@latest`

## Logs or screenshots
Paste relevant logs or add screenshots (redact secrets).

The output of `ollama list` is:
```
% ollama list
NAME                  ID              SIZE      MODIFIED       
deepseek-r1:latest    6995872bfe4c    5.2 GB    14 minutes ago   
```

## Comments

### @shivanraptor (2026-01-30)

In the log, it said: 

> Error: Unknown model: ollama/deepseek-r1:latest

### @spiceoogway (2026-01-30)

I've identified and fixed the issue! ðŸŽ‰

**Root Cause**: Ollama is a local service that doesn't require authentication, but the code was only enabling the Ollama provider if an API key was configured.

**Fix**: Modified the provider resolution logic to auto-discover Ollama models and add the provider if models are found (using "local" as a placeholder API key).

**PR**: #4667

The fix ensures that locally installed Ollama models will now be properly discovered and shown as available in `openclaw models list` without needing to configure a dummy API key.

### @Vector-Cross (2026-01-31)

What's the current progress? Has it been fixed and is now waiting to be merged into the main branch?


## Links

- None detected yet
